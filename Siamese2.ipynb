{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Siamese2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kkuntal990/CTW_2020/blob/master/Siamese2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjEwmtrg7sBN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a45dfac0-df89-4b24-e52b-5c2c7e883e4a"
      },
      "source": [
        "import psutil\n",
        "def get_size(bytes, suffix=\"B\"):\n",
        "    factor = 1024\n",
        "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n",
        "        if bytes < factor:\n",
        "            return f\"{bytes:.2f}{unit}{suffix}\"\n",
        "        bytes /= factor\n",
        "print(\"=\"*40, \"Memory Information\", \"=\"*40)\n",
        "svmem = psutil.virtual_memory()\n",
        "print(f\"Total: {get_size(svmem.total)}\") ; print(f\"Available: {get_size(svmem.available)}\")\n",
        "print(f\"Used: {get_size(svmem.used)}\") ; print(f\"Percentage: {svmem.percent}%\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "======================================== Memory Information ========================================\n",
            "Total: 25.51GB\n",
            "Available: 24.33GB\n",
            "Used: 832.95MB\n",
            "Percentage: 4.6%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL-9c6qz7zUQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "a9045d2f-4592-4a60-9746-17bdb670e0d9"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jul  9 15:56:30 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqpFkedI8Kbu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0bde4e75-802e-4677-ba4f-0ea7d182b741"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fesmFnEKGskw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "f = h5py.File(\"/content/gdrive/My Drive/CTW2020/Processed Data/udata2020.hdf5\",\"r\")\n",
        "import numpy as np\n",
        "_ , key = next(enumerate(f.keys()))\n",
        "X = f[key][:]\n",
        "f.close()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TZMmdAe-bDJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1839b7c9-2620-4f11-8494-07140587935c"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36192, 56, 924, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hos9jEq9cW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.sqrt(X[:,:,:,0]**2 + X[:,:,:,1]**2)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYGpSuWAPoil",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d53555ee-7e12-46b1-bfca-80db3eec01e0"
      },
      "source": [
        "import h5py\n",
        "f = h5py.File(\"/content/gdrive/My Drive/CTW2020/Processed Data/Labelled_1.hdf5\",\"r\")\n",
        "\n",
        "H = f[\"H_Est\"][:]\n",
        "Pos = f[\"Pos\"][:]\n",
        "SNR = f[\"SNR\"][:]\n",
        "f.close()\n",
        "\n",
        "print(H.shape)\n",
        "print(SNR.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4979, 56, 924, 2)\n",
            "(4979, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOk-lnxv9MRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "H = np.sqrt(H[:,:,:,0]**2 + H[:,:,:,1]**2)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U4rJbdh9nKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "H_Train, H_Test , Pos_Train , Pos_Test = train_test_split(H,Pos,test_size=0.1, random_state=42)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmZKU7tvakmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "import torch\n",
        "from torchsummary import summary\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import os\n",
        "from torchvision.utils import save_image\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCu8RSztap10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "H_Train, H_Val , Pos_Train , Pos_Val = train_test_split(H_Train,Pos_Train,test_size=0.1, random_state=99)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVmnIvvEVInY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62afa147-5ffb-4697-979f-200abb707579"
      },
      "source": [
        "print(H_Train.shape, H_Val.shape, H_Test.shape)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4032, 56, 924) (449, 56, 924) (498, 56, 924)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6el12NxbqAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "H_Train = torch.tensor(H_Train,dtype=torch.float)\n",
        "Pos_Train = torch.tensor(Pos_Train,dtype=torch.float)\n",
        "H_Val = torch.tensor(H_Val,dtype=torch.float)\n",
        "Pos_Val = torch.tensor(Pos_Val,dtype=torch.float)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3ue3vK55J8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Sammon(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Sammon, self).__init__()\n",
        "        \n",
        "        \n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(1,2, (2,4), stride=(1,2)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(2, 4, (2,4), stride=(1,4)),\n",
        "            nn.ReLU())\n",
        "        \n",
        "        self.Project = nn.Sequential(nn.Linear(49680,20000),\n",
        "                                     nn.Tanh(),\n",
        "                                     nn.Linear(20000,9000),\n",
        "                                     nn.Softplus(),\n",
        "                                     nn.Linear(9000,4500),\n",
        "                                     nn.Tanh(),)\n",
        "                                     \n",
        "          \n",
        "            \n",
        "    def forward(self, input):\n",
        "        return self.Project(self.main(input).view(-1,49680))\n",
        "\n",
        "\n",
        "class Regressor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Regressor, self).__init__()        \n",
        "        self.Project = nn.Sequential(nn.Linear(4500,2048),\n",
        "                                     nn.Tanh(),\n",
        "                                     nn.Linear(2048,1024),\n",
        "                                     nn.Softplus(),\n",
        "                                     nn.Linear(1024,512),\n",
        "                                     nn.Tanh(),\n",
        "                                     nn.Linear(512,256),\n",
        "                                     nn.Tanh(),\n",
        "                                     nn.Linear(256,128),\n",
        "                                     nn.Tanh(),\n",
        "                                     nn.Linear(128,64),\n",
        "                                     nn.Tanh(),\n",
        "                                     nn.Linear(64,32),\n",
        "                                     nn.Softplus(),\n",
        "                                     nn.Linear(32,16),\n",
        "                                     nn.Tanh(),\n",
        "                                     nn.Linear(16,8),\n",
        "                                     nn.Tanh(),\n",
        "                                     nn.Linear(8,3))\n",
        "          \n",
        "            \n",
        "    def forward(self, input):\n",
        "        return self.Project(input).view(-1,3)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7yfKTDJA-O7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
        "sammon = Sammon().to(device)\n",
        "reg = Regressor().to(device)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkGd-RUyBxdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt1 = optim.Adam(sammon.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
        "opt2 = optim.Adam(reg.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
        "MSE = nn.MSELoss()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd77lbbE9EIg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "ccd1635e-4d74-456f-8023-e0cd1b7afd92"
      },
      "source": [
        "summary(sammon, (1, 56,924))\n",
        "summary(reg, (4500,))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 2, 55, 461]              18\n",
            "              ReLU-2           [-1, 2, 55, 461]               0\n",
            "            Conv2d-3           [-1, 4, 54, 115]              68\n",
            "              ReLU-4           [-1, 4, 54, 115]               0\n",
            "            Linear-5                [-1, 20000]     993,620,000\n",
            "              Tanh-6                [-1, 20000]               0\n",
            "            Linear-7                 [-1, 9000]     180,009,000\n",
            "          Softplus-8                 [-1, 9000]               0\n",
            "            Linear-9                 [-1, 4500]      40,504,500\n",
            "             Tanh-10                 [-1, 4500]               0\n",
            "================================================================\n",
            "Total params: 1,214,133,586\n",
            "Trainable params: 1,214,133,586\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.20\n",
            "Forward/backward pass size (MB): 1.66\n",
            "Params size (MB): 4631.55\n",
            "Estimated Total Size (MB): 4633.41\n",
            "----------------------------------------------------------------\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                 [-1, 2048]       9,218,048\n",
            "              Tanh-2                 [-1, 2048]               0\n",
            "            Linear-3                 [-1, 1024]       2,098,176\n",
            "          Softplus-4                 [-1, 1024]               0\n",
            "            Linear-5                  [-1, 512]         524,800\n",
            "              Tanh-6                  [-1, 512]               0\n",
            "            Linear-7                  [-1, 256]         131,328\n",
            "              Tanh-8                  [-1, 256]               0\n",
            "            Linear-9                  [-1, 128]          32,896\n",
            "             Tanh-10                  [-1, 128]               0\n",
            "           Linear-11                   [-1, 64]           8,256\n",
            "             Tanh-12                   [-1, 64]               0\n",
            "           Linear-13                   [-1, 32]           2,080\n",
            "         Softplus-14                   [-1, 32]               0\n",
            "           Linear-15                   [-1, 16]             528\n",
            "             Tanh-16                   [-1, 16]               0\n",
            "           Linear-17                    [-1, 8]             136\n",
            "             Tanh-18                    [-1, 8]               0\n",
            "           Linear-19                    [-1, 3]              27\n",
            "================================================================\n",
            "Total params: 12,016,275\n",
            "Trainable params: 12,016,275\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.02\n",
            "Forward/backward pass size (MB): 0.06\n",
            "Params size (MB): 45.84\n",
            "Estimated Total Size (MB): 45.92\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpK2iU41cZEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = list(range(len(X)))*4\n",
        "pairs = []\n",
        "import random\n",
        "while len(A)>1:\n",
        "  t = random.randint(1,len(A)-1)\n",
        "  if(A[t]!=A[0]):\n",
        "    pairs.append((A[0],A[t]))\n",
        "    del A[0]\n",
        "    del A[t-1]\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnxcS8sie2Ix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pairs = np.array(pairs)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J9Kb_KS7kHc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a1ced14-508d-4fcb-930e-2fb8a2c7050f"
      },
      "source": [
        "pairs.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(72384, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JNeMIPNcPVR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "531d8e4b-4617-4775-87f6-a5d560b28285"
      },
      "source": [
        "N_b2 = len(H_Train)\n",
        "N_b = len(pairs)\n",
        "N_val = len(H_Val)\n",
        "bs1= 64\n",
        "bs2 = 8\n",
        "epsilon = 1e-6\n",
        "\n",
        "print(N_b2, N_b, N_val)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4032 72384 449\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvqLGR37VRxI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc55cb63-5dd3-4469-acf1-ed3d5c02673c"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36192, 56, 924)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB2wmMna1tFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss(XX, YY):\n",
        "  return torch.sum((1/XX)*(torch.square(XX-YY)))\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UKR9fGq5HOW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "f73c4bf0-f7ac-4842-ef28-075c218d3a9a"
      },
      "source": [
        "for i in range(100):\n",
        "  batch1=0\n",
        "  batch2=0\n",
        "  for j in range(0,N_b,bs1):\n",
        "    sammon.zero_grad()\n",
        "    end = min(j+bs1,N_b)\n",
        "    Xn,Xm = torch.tensor(X[pairs[j:end,0]],dtype=torch.float),  torch.tensor(X[pairs[j:end,1]],dtype=torch.float)\n",
        "    Xn , Xm = Variable(Xn, requires_grad=True) , Variable(Xm, requires_grad=True)\n",
        "    Xn = Xn.to(device)\n",
        "    Xm = Xm.to(device)\n",
        "    Yn = sammon(Xn.view(-1,1,56,924))\n",
        "    Ym = sammon(Xm.view(-1,1,56,924))\n",
        "    print(Xn.view(-1,1,56,924).shape, Yn.shape)\n",
        "\n",
        "    XX = torch.norm((Xn-Xm),p=2, dim = [1,2])\n",
        "    YY = torch.norm((Yn-Ym),p=2, dim = 1)\n",
        "    XX = torch.sqrt(torch.square(XX) + epsilon)\n",
        "    YY = torch.sqrt(torch.square(YY) + epsilon)\n",
        "    loss = custom_loss(XX, YY)\n",
        "    #print(loss)\n",
        "    loss.backward()\n",
        "    opt1.step()\n",
        "    batch1+=1\n",
        "    if(batch1%10 == 0):\n",
        "      print(\"Batch\",batch1,\"/\",(N_b//bs1)+1,\"Sammon Loss :\" , loss.item())\n",
        "\n",
        "  for k in range(0,N_b2,bs2):\n",
        "    end = min(k+bs2,N_b2)\n",
        "    H1 = H_Train[k:end]\n",
        "    sammon.zero_grad()\n",
        "    reg.zero_grad()\n",
        "    H1 = Variable(H1,requires_grad=True)\n",
        "    H1 = H1.to(device)\n",
        "    Y1 = reg(sammon(H1.view(-1,1,56,924)))\n",
        "    loss_1 = MSE(Y1,Pos_Train[k:end].to(device)).view(-1)\n",
        "    loss_1.backward()\n",
        "    opt1.step()\n",
        "    opt2.step()\n",
        "    batch2+=1\n",
        "    if(batch2%10 == 0):\n",
        "      print(\"Batch\",batch2,\"/\",(N_b2//bs2)+1,\"Regressor Loss :\" , loss_1.item())\n",
        "  print(\"Epoch \",i,\"/\",100,\" Sammon Loss :\",loss.item() ,\" Regressor Loss :\" , loss_1.item())\n",
        "  for l in range(N_val):\n",
        "    H_val = torch.tensor(H_Val[l],dtype=torch.float)\n",
        "    H_val = H_val.to(device)\n",
        "    with torch.no_grad():\n",
        "      Y_Val = reg(sammon(H_val.view(-1,1,56,924)))\n",
        "      loss_Val = MSE(Y_Val,Pos_Val[l].to(device)).view(-1)\n",
        "  print(\"Val Loss :\" , loss_Val.item())\n",
        "\n",
        "    \n",
        "\n",
        "      \n",
        "  \n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 56, 924]) torch.Size([32, 4500])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-66a9c1422883>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mXX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mYY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m#print(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-27a921691f4c>\u001b[0m in \u001b[0;36mcustom_loss\u001b[0;34m(XX, YY)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcustom_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mYY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (32) at non-singleton dimension 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9XdPuF1wTAH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "34cb9a52-83cf-4ece-e856-610de038cdc0"
      },
      "source": [
        "pairs[2:9,0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3, 4, 5, 6, 7, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    }
  ]
}