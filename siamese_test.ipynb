{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "siamese_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMpHWFKoZrRs85CO3Wr150C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kkuntal990/CTW_2020/blob/master/siamese_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvFRkfR3phod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorflow_version 1.x\n",
        "import numpy as np # linear algebra\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import h5py\n",
        "import pandas as pd\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aksvzc2ytrCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Dense, LeakyReLU, Input, Conv2D, AveragePooling2D, MaxPooling2D, Dropout, Flatten, concatenate, Input, BatchNormalization, UpSampling2D\n",
        "import tensorflow.keras.backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE1ek6oxtxmP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80d8c064-92d6-4ef8-f4d7-3010bc2556e6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYPXrT-supvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(data_file):\n",
        "    f = h5py.File(data_file, 'r')\n",
        "    H_Re = f['H_Re'][:] #shape (sample size, 56, 924, 5)\n",
        "    H_Im = f['H_Im'][:] #shape (sample size, 56, 924, 5)\n",
        "    SNR = f['SNR'][:] #shape (sample size, 56, 5)\n",
        "    Pos = f['Pos'][:] #shape(sample size, 3)\n",
        "    f.close()\n",
        "    return H_Re, H_Im, SNR, Pos\n",
        "\n",
        "def get_udata(data_file):\n",
        "    f = h5py.File(data_file, 'r')\n",
        "    print(f.keys())\n",
        "    H_Re = f['H_Est'][:]\n",
        "    f.close()\n",
        "    return H_Re\n",
        "\n",
        "def show_keys(data_file):\n",
        "    f = h5py.File(data_file, 'r')\n",
        "    for idx, key in enumerate(f.keys()):\n",
        "      print(key, end=\" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvaXA9GJvF4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "H = get_udata('/content/drive/My Drive/CTW2020/Processed Data/udata2020.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iyUjIlJMaeW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "idx, idx_t = train_test_split(list(range(H.shape[0])), test_size=0.15, random_state=42, shuffle=True)\n",
        "H= H[idx, :, :, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMQywWqH4FuN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(H.shape)\n",
        "H, H_v = train_test_split(H, test_size = 0.12, random_state = 54, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhaUe1kgzk1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Siamese_CC(inp_dim):\n",
        "  input = Input(shape = (inp_dim))\n",
        "  x = Conv2D(4,(3,9), padding='same',activation='relu', kernel_initializer='glorot_uniform')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPooling2D((1, 2), padding='same')(x)   \n",
        "  x = Conv2D(8,(3,3), padding='same',activation='relu', kernel_initializer='glorot_uniform')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPooling2D((1, 3), padding='same')(x)\n",
        "  x = Conv2D(16,(2,4), padding='same',activation='relu', kernel_initializer='glorot_uniform')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPooling2D((1, 1), padding='same')(x)\n",
        "  x = Conv2D(32,(2,2), padding='same',activation='relu', kernel_initializer='glorot_uniform')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  encoded = MaxPooling2D((1,2), padding='same')(x)\n",
        "  x = Conv2D(32,(2,2), padding='same',activation='relu', kernel_initializer='glorot_uniform')(encoded)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = UpSampling2D((1,2))(x)\n",
        "  x = Conv2D(16,(2,4), padding='same',activation='relu', kernel_initializer='glorot_uniform')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = UpSampling2D((1,1))(x)\n",
        "  x = Conv2D(8,(2,4), padding='same',activation='relu', kernel_initializer='glorot_uniform')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = UpSampling2D((1, 3))(x)\n",
        "  x = Conv2D(4,(3,3), padding='same',activation='relu', kernel_initializer='glorot_uniform')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = UpSampling2D((1, 2))(x)\n",
        "  decoded = Conv2D(2,(3,9), padding='same',activation='relu', kernel_initializer='glorot_uniform')(x)\n",
        "  return Model(input,encoded), Model(input, decoded)\n",
        "\n",
        "\n",
        "\n",
        "def data_gen(data, BS):\n",
        "    for i in range(0,len(data),BS):\n",
        "        if i + BS > len(data)-1:\n",
        "            yield (data[i:], data[i:])\n",
        "        else:\n",
        "            yield (data[i:i+BS],data[i:i+BS])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUUlqRBAEXNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Encoder, Decoder = Siamese_CC((56,924,2))\n",
        "Decoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pva20sypGMfv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "50431a4a-fe2b-4503-d1bf-9420cc91bc59"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "earlystopper = EarlyStopping(patience = 30, verbose=1)\n",
        "checkpointer = ModelCheckpoint('2/content/drive/My Drive/CTW2020/020_ae_test.h5', verbose=1, save_best_only=True)\n",
        "Decoder.compile(optimizer='Adam', loss='mean_squared_error')\n",
        "\n",
        "bs = 400   #batch size of the data\n",
        "for i in range(200):\n",
        "  Decoder.fit_generator(data_gen(H, bs), epochs=1,steps_per_epoch= len(H)//bs, verbose=1, validation_data= data_gen(H_v, bs), \n",
        "                      validation_steps = len(H_v)//bs, callbacks=[earlystopper, checkpointer],shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-10-b834aa3ad9b2>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.1765\n",
            "Epoch 00001: val_loss improved from inf to 0.04701, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 62s 2s/step - loss: 0.1765 - val_loss: 0.0470\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0623\n",
            "Epoch 00001: val_loss did not improve from 0.04701\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0623 - val_loss: 0.0471\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0545\n",
            "Epoch 00001: val_loss did not improve from 0.04701\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0545 - val_loss: 0.0470\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0509\n",
            "Epoch 00001: val_loss improved from 0.04701 to 0.04655, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0509 - val_loss: 0.0465\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0470\n",
            "Epoch 00001: val_loss improved from 0.04655 to 0.04381, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0470 - val_loss: 0.0438\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0437\n",
            "Epoch 00001: val_loss improved from 0.04381 to 0.04047, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0437 - val_loss: 0.0405\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0411\n",
            "Epoch 00001: val_loss improved from 0.04047 to 0.03715, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0411 - val_loss: 0.0372\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0391\n",
            "Epoch 00001: val_loss improved from 0.03715 to 0.03404, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0391 - val_loss: 0.0340\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0376\n",
            "Epoch 00001: val_loss improved from 0.03404 to 0.03200, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0376 - val_loss: 0.0320\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0364\n",
            "Epoch 00001: val_loss improved from 0.03200 to 0.03090, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0364 - val_loss: 0.0309\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0355\n",
            "Epoch 00001: val_loss improved from 0.03090 to 0.03047, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0355 - val_loss: 0.0305\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0349\n",
            "Epoch 00001: val_loss improved from 0.03047 to 0.03021, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0349 - val_loss: 0.0302\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0343\n",
            "Epoch 00001: val_loss improved from 0.03021 to 0.02999, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0343 - val_loss: 0.0300\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0340\n",
            "Epoch 00001: val_loss improved from 0.02999 to 0.02979, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0340 - val_loss: 0.0298\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0336\n",
            "Epoch 00001: val_loss improved from 0.02979 to 0.02961, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0336 - val_loss: 0.0296\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0334\n",
            "Epoch 00001: val_loss improved from 0.02961 to 0.02948, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0334 - val_loss: 0.0295\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0331\n",
            "Epoch 00001: val_loss improved from 0.02948 to 0.02931, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0331 - val_loss: 0.0293\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0330\n",
            "Epoch 00001: val_loss improved from 0.02931 to 0.02909, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0330 - val_loss: 0.0291\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0328\n",
            "Epoch 00001: val_loss improved from 0.02909 to 0.02886, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0328 - val_loss: 0.0289\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0327\n",
            "Epoch 00001: val_loss improved from 0.02886 to 0.02863, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0327 - val_loss: 0.0286\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0325\n",
            "Epoch 00001: val_loss improved from 0.02863 to 0.02843, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0325 - val_loss: 0.0284\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0324\n",
            "Epoch 00001: val_loss improved from 0.02843 to 0.02826, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0324 - val_loss: 0.0283\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0323\n",
            "Epoch 00001: val_loss improved from 0.02826 to 0.02810, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0323 - val_loss: 0.0281\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0323\n",
            "Epoch 00001: val_loss improved from 0.02810 to 0.02797, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0323 - val_loss: 0.0280\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0322\n",
            "Epoch 00001: val_loss improved from 0.02797 to 0.02784, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0322 - val_loss: 0.0278\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0321\n",
            "Epoch 00001: val_loss improved from 0.02784 to 0.02771, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0321 - val_loss: 0.0277\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0321\n",
            "Epoch 00001: val_loss improved from 0.02771 to 0.02759, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0321 - val_loss: 0.0276\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0320\n",
            "Epoch 00001: val_loss improved from 0.02759 to 0.02748, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0320 - val_loss: 0.0275\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0319\n",
            "Epoch 00001: val_loss improved from 0.02748 to 0.02738, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0319 - val_loss: 0.0274\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0319\n",
            "Epoch 00001: val_loss improved from 0.02738 to 0.02729, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0319 - val_loss: 0.0273\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0318\n",
            "Epoch 00001: val_loss improved from 0.02729 to 0.02722, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0318 - val_loss: 0.0272\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0318\n",
            "Epoch 00001: val_loss improved from 0.02722 to 0.02715, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0318 - val_loss: 0.0272\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0317\n",
            "Epoch 00001: val_loss improved from 0.02715 to 0.02709, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0317 - val_loss: 0.0271\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0317\n",
            "Epoch 00001: val_loss improved from 0.02709 to 0.02703, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0317 - val_loss: 0.0270\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0316\n",
            "Epoch 00001: val_loss improved from 0.02703 to 0.02698, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0316 - val_loss: 0.0270\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0316\n",
            "Epoch 00001: val_loss improved from 0.02698 to 0.02693, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0316 - val_loss: 0.0269\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0316\n",
            "Epoch 00001: val_loss improved from 0.02693 to 0.02688, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0316 - val_loss: 0.0269\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0315\n",
            "Epoch 00001: val_loss improved from 0.02688 to 0.02684, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0315 - val_loss: 0.0268\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0315\n",
            "Epoch 00001: val_loss improved from 0.02684 to 0.02680, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0315 - val_loss: 0.0268\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0315\n",
            "Epoch 00001: val_loss improved from 0.02680 to 0.02676, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0315 - val_loss: 0.0268\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0315\n",
            "Epoch 00001: val_loss improved from 0.02676 to 0.02673, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0315 - val_loss: 0.0267\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0314\n",
            "Epoch 00001: val_loss improved from 0.02673 to 0.02670, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0314 - val_loss: 0.0267\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0314\n",
            "Epoch 00001: val_loss improved from 0.02670 to 0.02667, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0314 - val_loss: 0.0267\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0314\n",
            "Epoch 00001: val_loss improved from 0.02667 to 0.02665, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0314 - val_loss: 0.0266\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0314\n",
            "Epoch 00001: val_loss improved from 0.02665 to 0.02662, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0314 - val_loss: 0.0266\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0313\n",
            "Epoch 00001: val_loss improved from 0.02662 to 0.02660, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0313 - val_loss: 0.0266\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0313\n",
            "Epoch 00001: val_loss improved from 0.02660 to 0.02658, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0313 - val_loss: 0.0266\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0313\n",
            "Epoch 00001: val_loss improved from 0.02658 to 0.02656, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0313 - val_loss: 0.0266\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0313\n",
            "Epoch 00001: val_loss improved from 0.02656 to 0.02655, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0313 - val_loss: 0.0265\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0313\n",
            "Epoch 00001: val_loss improved from 0.02655 to 0.02653, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0313 - val_loss: 0.0265\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0313\n",
            "Epoch 00001: val_loss improved from 0.02653 to 0.02652, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0313 - val_loss: 0.0265\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0313\n",
            "Epoch 00001: val_loss improved from 0.02652 to 0.02650, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0313 - val_loss: 0.0265\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0312\n",
            "Epoch 00001: val_loss improved from 0.02650 to 0.02649, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0312 - val_loss: 0.0265\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0312\n",
            "Epoch 00001: val_loss improved from 0.02649 to 0.02648, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0312 - val_loss: 0.0265\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0312\n",
            "Epoch 00001: val_loss improved from 0.02648 to 0.02646, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0312 - val_loss: 0.0265\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0312\n",
            "Epoch 00001: val_loss improved from 0.02646 to 0.02645, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0312 - val_loss: 0.0265\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0312\n",
            "Epoch 00001: val_loss improved from 0.02645 to 0.02644, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0312 - val_loss: 0.0264\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0312\n",
            "Epoch 00001: val_loss improved from 0.02644 to 0.02643, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0312 - val_loss: 0.0264\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0312\n",
            "Epoch 00001: val_loss improved from 0.02643 to 0.02642, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0312 - val_loss: 0.0264\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0312\n",
            "Epoch 00001: val_loss improved from 0.02642 to 0.02641, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0312 - val_loss: 0.0264\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0311\n",
            "Epoch 00001: val_loss improved from 0.02641 to 0.02640, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0311 - val_loss: 0.0264\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0311\n",
            "Epoch 00001: val_loss improved from 0.02640 to 0.02639, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0311 - val_loss: 0.0264\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0311\n",
            "Epoch 00001: val_loss improved from 0.02639 to 0.02638, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0311 - val_loss: 0.0264\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0311\n",
            "Epoch 00001: val_loss improved from 0.02638 to 0.02637, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0311 - val_loss: 0.0264\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0311\n",
            "Epoch 00001: val_loss improved from 0.02637 to 0.02636, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0311 - val_loss: 0.0264\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0311\n",
            "Epoch 00001: val_loss improved from 0.02636 to 0.02635, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0311 - val_loss: 0.0264\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0311\n",
            "Epoch 00001: val_loss improved from 0.02635 to 0.02634, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0311 - val_loss: 0.0263\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0311\n",
            "Epoch 00001: val_loss improved from 0.02634 to 0.02633, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0311 - val_loss: 0.0263\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0311\n",
            "Epoch 00001: val_loss improved from 0.02633 to 0.02632, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0311 - val_loss: 0.0263\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0311\n",
            "Epoch 00001: val_loss improved from 0.02632 to 0.02631, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0311 - val_loss: 0.0263\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0311\n",
            "Epoch 00001: val_loss improved from 0.02631 to 0.02630, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0311 - val_loss: 0.0263\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0311\n",
            "Epoch 00001: val_loss improved from 0.02630 to 0.02629, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 61s 2s/step - loss: 0.0311 - val_loss: 0.0263\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0311\n",
            "Epoch 00001: val_loss improved from 0.02629 to 0.02629, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0311 - val_loss: 0.0263\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0311\n",
            "Epoch 00001: val_loss improved from 0.02629 to 0.02628, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0311 - val_loss: 0.0263\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02628 to 0.02627, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0263\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02627 to 0.02626, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0263\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02626 to 0.02626, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0263\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02626 to 0.02625, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02625 to 0.02624, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02624 to 0.02623, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02623 to 0.02623, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02623 to 0.02622, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02622 to 0.02622, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02622 to 0.02621, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02621 to 0.02621, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02621 to 0.02620, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02620 to 0.02620, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02620 to 0.02619, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02619 to 0.02619, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02619 to 0.02619, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02619 to 0.02618, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02618 to 0.02618, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02618 to 0.02617, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02617 to 0.02617, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02617 to 0.02617, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02617 to 0.02617, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02617 to 0.02616, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02616 to 0.02616, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0310\n",
            "Epoch 00001: val_loss improved from 0.02616 to 0.02616, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0310 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 00001: val_loss improved from 0.02616 to 0.02616, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0309 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 00001: val_loss improved from 0.02616 to 0.02616, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0309 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 00001: val_loss improved from 0.02616 to 0.02615, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0309 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 00001: val_loss improved from 0.02615 to 0.02615, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0309 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 00001: val_loss improved from 0.02615 to 0.02615, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0309 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 00001: val_loss improved from 0.02615 to 0.02615, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0309 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 00001: val_loss improved from 0.02615 to 0.02615, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0309 - val_loss: 0.0261\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 00001: val_loss improved from 0.02615 to 0.02615, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0309 - val_loss: 0.0261\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 00001: val_loss improved from 0.02615 to 0.02615, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0309 - val_loss: 0.0261\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 00001: val_loss improved from 0.02615 to 0.02615, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0309 - val_loss: 0.0261\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 00001: val_loss improved from 0.02615 to 0.02615, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0309 - val_loss: 0.0261\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 00001: val_loss did not improve from 0.02615\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0309 - val_loss: 0.0261\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 00001: val_loss improved from 0.02615 to 0.02615, saving model to 2/content/drive/My Drive/CTW2020/020_ae_test.h5\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0309 - val_loss: 0.0261\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 00001: val_loss did not improve from 0.02615\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0309 - val_loss: 0.0261\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 00001: val_loss did not improve from 0.02615\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0309 - val_loss: 0.0261\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 00001: val_loss did not improve from 0.02615\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0309 - val_loss: 0.0261\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 00001: val_loss did not improve from 0.02615\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0309 - val_loss: 0.0261\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 00001: val_loss did not improve from 0.02615\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0309 - val_loss: 0.0261\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 00001: val_loss did not improve from 0.02615\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0309 - val_loss: 0.0261\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 00001: val_loss did not improve from 0.02615\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0309 - val_loss: 0.0261\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 00001: val_loss did not improve from 0.02615\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0309 - val_loss: 0.0261\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 00001: val_loss did not improve from 0.02615\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0309 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 00001: val_loss did not improve from 0.02615\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0309 - val_loss: 0.0262\n",
            "31/31 [==============================] - ETA: 0s - loss: 0.0309\n",
            "Epoch 00001: val_loss did not improve from 0.02615\n",
            "31/31 [==============================] - 60s 2s/step - loss: 0.0309 - val_loss: 0.0262\n",
            " 9/31 [=======>......................] - ETA: 37s - loss: 0.0298"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-b834aa3ad9b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   Decoder.fit_generator(data_gen(H, bs), epochs=1,steps_per_epoch= len(H)//bs, verbose=1, validation_data= data_gen(H_v, bs), \n\u001b[0;32m----> 9\u001b[0;31m                       validation_steps = len(H_v)//bs, callbacks=[earlystopper, checkpointer],shuffle=True)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1477\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m   @deprecation.deprecated(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sqQExvCOZOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Siamese_SS(inp_dim):\n",
        "  inp1 = Input(shape=(inp_dim))\n",
        "  inp2 = Input(shape=(inp_dim))\n",
        "\n",
        "  enc1 = Encoder(inputs=inp1)\n",
        "  enc2 = Encoder(inputs=inp2)\n",
        "\n",
        "  x = Dense(2048, )    \n",
        "  \n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}