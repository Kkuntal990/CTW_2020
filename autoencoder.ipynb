{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd\nimport pyarrow.parquet as pq\nimport os\nprint(os.listdir(\"../input\"))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom tensorflow.python.keras.models import Sequential, Model, load_model\nfrom tensorflow.python.keras.layers import Dense\nimport numpy as np\nimport os\nimport h5py\n#from keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.decomposition import PCA","execution_count":1,"outputs":[{"output_type":"stream","text":"['weights-1', 'traindata', 'dsadasd']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find(SNR):\n    #H_R.shape = (512,56,924,5)\n    temp = np.sum(SNR**2, axis=1)\n    #print(temp.shape)\n    idx  = np.argmax(temp, axis=1)\n    return idx\n    \ndef preprocess(H_Re, idx):\n    temp = np.zeros(H_Re.shape[:-1])\n    for i in range(H_Re.shape[0]):\n        temp[i] = H_Re[i,:,:,idx[i]]\n    return temp\n\ndef preprocess2(H_Re, idx):\n    temp = np.zeros(H_Re.shape[:-1])\n    for i in range(H_Re.shape[0]):\n        temp[i] = H_Re[i,:,idx[i]]\n    return temp\n      \n        ","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def get_data(data_file):\n    f = h5py.File(data_file, 'r')\n    H_Re = f['H_Re'][:] #shape (sample size, 56, 924, 5)\n    H_Im = f['H_Im'][:] #shape (sample size, 56, 924, 5)\n    SNR = f['SNR'][:] #shape (sample size, 56, 5)\n    Pos = f['Pos'][:] #shape(sample size, 3)\n    f.close()\n    return H_Re, H_Im, SNR, Pos\n\nCTW_labelled = \"../input/traindata\"\ndata_file = CTW_labelled+\"/file_\"+str(1)+\".hdf5\"\nH_Re, H_Im, SNR, Pos = get_data(data_file)\n\n#print(H_Re[1,1,1,:])\n\nidx = find(SNR)\n\nH_Re = preprocess(H_Re, idx)\nH_Im = preprocess(H_Im, idx)\nSNR = preprocess2(SNR, idx)\n#print(SNR.shape)\n\n","execution_count":6,"outputs":[{"output_type":"stream","text":"[[  15.41993422   20.02795521 -100.         ...   20.20389977\n    20.98391009   13.45937879]\n [  14.87486152   15.71887731   12.85714942 ...   20.89376565\n    20.68049551   23.21826983]\n [-100.           10.50935505 -100.         ...   22.51211621\n    21.43964909   21.95467171]\n ...\n [-100.         -100.         -100.         ... -100.\n  -100.         -100.        ]\n [  17.78958193   16.50816507 -100.         ...   22.56948133\n    18.74475369   21.48719758]\n [-100.         -100.         -100.         ... -100.\n  -100.         -100.        ]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(2,3):\n    temp = CTW_labelled+\"/file_\"+str(i)+\".hdf5\"\n    tH_Re, tH_Im, tSNR, tPos = get_data(temp)\n    idx = find(tSNR)\n    tH_Re = preprocess(tH_Re, idx)\n    tH_Im = preprocess(tH_Im, idx)\n    tSNR = preprocess2(tSNR, idx)\n    H_Re, H_Im, Pos, SNR  = np.concatenate((H_Re, tH_Re)), np.concatenate((H_Im, tH_Im)), np.concatenate((Pos, tPos)), np.concatenate((SNR, tSNR))","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(H_Re[:,1,1])\n\nsamples = H_Re.shape[0]\nH_Re = H_Re.reshape((samples,-1))\nprint(H_Re.shape)\nH_Im = H_Im.reshape((samples,-1))\n#SNR = SNR.reshape((samples,-1))\n#Pos = Pos.reshape((samples,-1))\n\ndata = np.concatenate((H_Re, H_Im, SNR), axis=1)\nprint(data.shape)\n","execution_count":8,"outputs":[{"output_type":"stream","text":"(1024, 51744)\n(1024, 103544)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=24)\no = pca.fit_transform(data[:1000])\ny = pca.explained_variance_ratio_\n#x = np.linspace(1,data[:1000].shape[1], data[:1000].shape[1])\n#plt.plot(x,y)\nprint(o.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data[:int(data.shape[0]/5)].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n\nmodel = Sequential()\nmodel.add(Dense(compression_1, activation = 'relu', input_shape=(517718,), name = 'compress'))\nmodel.add(Dense(517718, activation='linear'))\nmodel.compile(loss= 'mean_squared_error', optimizer = 'adam')\n#model.loadweights('../input/weights_1/saved_model.pb')\n#print('model summary')\n'''\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    model = tf.keras.Sequential([ tf.keras.layers.Dense(20, activation='relu', input_shape=(103544,), name='compress'),\n                           tf.keras.layers.Dense(103544, activation='linear')])\n    model.compile(loss= 'mean_squared_error', optimizer = 'adam') \n    return model\nprint(data.shape)","execution_count":9,"outputs":[{"output_type":"stream","text":"(1024, 103544)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#compression_1 = 20\nmodel = create_model()\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nearlystopper = EarlyStopping(patience = 3, verbose=1)\ncheckpointer = ModelCheckpoint('Best', verbose=1, save_best_only=True)\nresults = model.fit(data[:1000], data[:1000], validation_split=0.1, batch_size = 10, epochs = 100, callbacks=[earlystopper, checkpointer])\nmodel.save('mymodel.h5')","execution_count":10,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"},{"output_type":"stream","text":"Train on 900 samples, validate on 100 samples\nEpoch 1/100\n890/900 [============================>.] - ETA: 0s - loss: 1.7168\nEpoch 00001: val_loss improved from inf to 0.69042, saving model to Best\n900/900 [==============================] - 4s 5ms/sample - loss: 1.7094 - val_loss: 0.6904\nEpoch 2/100\n890/900 [============================>.] - ETA: 0s - loss: 0.6393\nEpoch 00002: val_loss improved from 0.69042 to 0.56697, saving model to Best\n900/900 [==============================] - 3s 3ms/sample - loss: 0.6381 - val_loss: 0.5670\nEpoch 3/100\n870/900 [============================>.] - ETA: 0s - loss: 0.5876\nEpoch 00003: val_loss improved from 0.56697 to 0.55504, saving model to Best\n900/900 [==============================] - 3s 4ms/sample - loss: 0.5858 - val_loss: 0.5550\nEpoch 4/100\n880/900 [============================>.] - ETA: 0s - loss: 0.5688\nEpoch 00004: val_loss improved from 0.55504 to 0.53770, saving model to Best\n900/900 [==============================] - 3s 3ms/sample - loss: 0.5686 - val_loss: 0.5377\nEpoch 5/100\n870/900 [============================>.] - ETA: 0s - loss: 0.5469\nEpoch 00005: val_loss improved from 0.53770 to 0.50941, saving model to Best\n900/900 [==============================] - 3s 3ms/sample - loss: 0.5467 - val_loss: 0.5094\nEpoch 6/100\n890/900 [============================>.] - ETA: 0s - loss: 0.5255\nEpoch 00006: val_loss improved from 0.50941 to 0.49005, saving model to Best\n900/900 [==============================] - 3s 3ms/sample - loss: 0.5255 - val_loss: 0.4901\nEpoch 7/100\n880/900 [============================>.] - ETA: 0s - loss: 0.5045\nEpoch 00007: val_loss improved from 0.49005 to 0.48189, saving model to Best\n900/900 [==============================] - 3s 3ms/sample - loss: 0.5044 - val_loss: 0.4819\nEpoch 8/100\n890/900 [============================>.] - ETA: 0s - loss: 0.4917\nEpoch 00008: val_loss improved from 0.48189 to 0.46757, saving model to Best\n900/900 [==============================] - 3s 3ms/sample - loss: 0.4922 - val_loss: 0.4676\nEpoch 9/100\n880/900 [============================>.] - ETA: 0s - loss: 0.4950\nEpoch 00009: val_loss improved from 0.46757 to 0.46377, saving model to Best\n900/900 [==============================] - 3s 3ms/sample - loss: 0.4941 - val_loss: 0.4638\nEpoch 10/100\n890/900 [============================>.] - ETA: 0s - loss: 0.4981\nEpoch 00010: val_loss improved from 0.46377 to 0.45635, saving model to Best\n900/900 [==============================] - 3s 3ms/sample - loss: 0.4968 - val_loss: 0.4564\nEpoch 11/100\n870/900 [============================>.] - ETA: 0s - loss: 0.4752\nEpoch 00011: val_loss did not improve from 0.45635\n900/900 [==============================] - 2s 3ms/sample - loss: 0.4782 - val_loss: 0.4780\nEpoch 12/100\n880/900 [============================>.] - ETA: 0s - loss: 0.4785\nEpoch 00012: val_loss improved from 0.45635 to 0.45248, saving model to Best\n900/900 [==============================] - 3s 3ms/sample - loss: 0.4810 - val_loss: 0.4525\nEpoch 13/100\n880/900 [============================>.] - ETA: 0s - loss: 0.4608\nEpoch 00013: val_loss improved from 0.45248 to 0.44291, saving model to Best\n900/900 [==============================] - 3s 3ms/sample - loss: 0.4635 - val_loss: 0.4429\nEpoch 14/100\n880/900 [============================>.] - ETA: 0s - loss: 0.4729\nEpoch 00014: val_loss did not improve from 0.44291\n900/900 [==============================] - 2s 3ms/sample - loss: 0.4722 - val_loss: 0.4624\nEpoch 15/100\n890/900 [============================>.] - ETA: 0s - loss: 0.4707\nEpoch 00015: val_loss did not improve from 0.44291\n900/900 [==============================] - 2s 3ms/sample - loss: 0.4717 - val_loss: 0.4511\nEpoch 16/100\n890/900 [============================>.] - ETA: 0s - loss: 0.4591\nEpoch 00016: val_loss improved from 0.44291 to 0.42855, saving model to Best\n900/900 [==============================] - 3s 3ms/sample - loss: 0.4593 - val_loss: 0.4285\nEpoch 17/100\n870/900 [============================>.] - ETA: 0s - loss: 0.4534\nEpoch 00017: val_loss did not improve from 0.42855\n900/900 [==============================] - 2s 3ms/sample - loss: 0.4547 - val_loss: 0.4368\nEpoch 18/100\n880/900 [============================>.] - ETA: 0s - loss: 0.4487\nEpoch 00018: val_loss improved from 0.42855 to 0.42789, saving model to Best\n900/900 [==============================] - 3s 3ms/sample - loss: 0.4485 - val_loss: 0.4279\nEpoch 19/100\n890/900 [============================>.] - ETA: 0s - loss: 0.4423\nEpoch 00019: val_loss did not improve from 0.42789\n900/900 [==============================] - 2s 3ms/sample - loss: 0.4444 - val_loss: 0.4325\nEpoch 20/100\n890/900 [============================>.] - ETA: 0s - loss: 0.4430\nEpoch 00020: val_loss improved from 0.42789 to 0.42656, saving model to Best\n900/900 [==============================] - 3s 3ms/sample - loss: 0.4418 - val_loss: 0.4266\nEpoch 21/100\n880/900 [============================>.] - ETA: 0s - loss: 0.4388\nEpoch 00021: val_loss improved from 0.42656 to 0.42172, saving model to Best\n900/900 [==============================] - 3s 3ms/sample - loss: 0.4376 - val_loss: 0.4217\nEpoch 22/100\n890/900 [============================>.] - ETA: 0s - loss: 0.4354\nEpoch 00022: val_loss improved from 0.42172 to 0.41269, saving model to Best\n900/900 [==============================] - 3s 4ms/sample - loss: 0.4348 - val_loss: 0.4127\nEpoch 23/100\n880/900 [============================>.] - ETA: 0s - loss: 0.4316\nEpoch 00023: val_loss did not improve from 0.41269\n900/900 [==============================] - 3s 3ms/sample - loss: 0.4313 - val_loss: 0.4412\nEpoch 24/100\n880/900 [============================>.] - ETA: 0s - loss: 0.4366\nEpoch 00024: val_loss improved from 0.41269 to 0.40708, saving model to Best\n900/900 [==============================] - 3s 3ms/sample - loss: 0.4350 - val_loss: 0.4071\nEpoch 25/100\n880/900 [============================>.] - ETA: 0s - loss: 0.4249\nEpoch 00025: val_loss did not improve from 0.40708\n900/900 [==============================] - 2s 3ms/sample - loss: 0.4235 - val_loss: 0.4089\nEpoch 26/100\n870/900 [============================>.] - ETA: 0s - loss: 0.4317\nEpoch 00026: val_loss improved from 0.40708 to 0.40620, saving model to Best\n900/900 [==============================] - 3s 3ms/sample - loss: 0.4306 - val_loss: 0.4062\nEpoch 27/100\n880/900 [============================>.] - ETA: 0s - loss: 0.4172\nEpoch 00027: val_loss improved from 0.40620 to 0.40188, saving model to Best\n900/900 [==============================] - 3s 3ms/sample - loss: 0.4172 - val_loss: 0.4019\nEpoch 28/100\n890/900 [============================>.] - ETA: 0s - loss: 0.4217\nEpoch 00028: val_loss did not improve from 0.40188\n900/900 [==============================] - 2s 3ms/sample - loss: 0.4219 - val_loss: 0.4058\nEpoch 29/100\n890/900 [============================>.] - ETA: 0s - loss: 0.4180\nEpoch 00029: val_loss did not improve from 0.40188\n900/900 [==============================] - 2s 3ms/sample - loss: 0.4164 - val_loss: 0.4032\nEpoch 30/100\n880/900 [============================>.] - ETA: 0s - loss: 0.4354\nEpoch 00030: val_loss did not improve from 0.40188\n900/900 [==============================] - 2s 3ms/sample - loss: 0.4361 - val_loss: 0.4301\nEpoch 00030: early stopping\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data[1002])\nprint(np.sum(((model.predict(data[1001:])[0])-data[1001])**2)/103544)","execution_count":12,"outputs":[{"output_type":"stream","text":"[   0.    0.    0. ... -100. -100. -100.]\n0.01730572994244381\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = model.fit(data[int(data.shape[0]/5):2*int(data.shape[0]/5)], data[int(data.shape[0]/5):2*int(data.shape[0]/5)], validation_split=0.1, batch_size = 10, epochs = 100, callbacks=[earlystopper, checkpointer])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = model.fit(data[2*int(data.shape[0]/5):3*int(data.shape[0]/5)], data[2*int(data.shape[0]/5):3*int(data.shape[0]/5)], validation_split=0.1, batch_size = 10, epochs = 100, callbacks=[earlystopper, checkpointer])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_model = create_model()\n#print(os.listdir(\"../output\"))\n\nc_model = load_model('../input/dsadasd/Best')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_decompressed = c_model.predict(data[0:6])\nprint(np.sum((X_decompressed - data[0:6])**2)/517784*6)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
