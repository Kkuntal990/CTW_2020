{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020PCA+CNN",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RJB_zS6Y_o5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "24cd044a-3345-4062-d327-6881b6b1fb59"
      },
      "source": [
        "!pip install gpustat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gpustat\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/69/d8c849715171aeabd61af7da080fdc60948b5a396d2422f1f4672e43d008/gpustat-0.6.0.tar.gz (78kB)\n",
            "\r\u001b[K     |████▏                           | 10kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 30kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 40kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 51kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 61kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from gpustat) (1.12.0)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from gpustat) (7.352.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from gpustat) (5.4.8)\n",
            "Collecting blessings>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/03/74/489f85a78247609c6b4f13733cbf3ba0d864b11aa565617b645d6fdf2a4a/blessings-1.7-py3-none-any.whl\n",
            "Building wheels for collected packages: gpustat\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-0.6.0-cp36-none-any.whl size=12622 sha256=41659bfaf9c8166b24ae4d3f3b5588d4fba586f1ef38deb4fcd489b90b97b8d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/b4/d5/fb5b7f1d040f2ff20687e3bad6867d63155dbde5a7c10f4293\n",
            "Successfully built gpustat\n",
            "Installing collected packages: blessings, gpustat\n",
            "Successfully installed blessings-1.7 gpustat-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhlIsJ3SZrGZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6794f321-446e-4d86-be3c-880f2fc05f00"
      },
      "source": [
        "!gpustat -cp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[37me09b70d4caf0           \u001b[m  Sun Jul 12 08:29:04 2020  \u001b[1m\u001b[30m418.67\u001b[m\n",
            "\u001b[36m[0]\u001b[m \u001b[34mTesla P100-PCIE-16GB\u001b[m |\u001b[1m\u001b[31m 56'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m16280\u001b[m MB |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fesmFnEKGskw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "f = h5py.File(\"/content/drive/My Drive/CTW2020/Processed Data/udata2020.hdf5\",\"r\")\n",
        "import numpy as np\n",
        "X = f[\"H_Est\"][:].transpose(0,3,1,2)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQArtpeUPJl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X.transpose(0,2,3,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z5wZTOxO-aB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.sqrt(X[:,:,:,0]**2 + X[:,:,:,1]**2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hos9jEq9cW6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0824a87f-7c32-4720-8c8b-8a4b4ee8a0de"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36192, 56, 924)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYGpSuWAPoil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "f = h5py.File(\"/content/drive/My Drive/CTW2020/Processed Data/Labelled_1.hdf5\",\"r\")\n",
        "H = f[\"H_Est\"][:]\n",
        "Pos = f[\"Pos\"][:]\n",
        "SNR = f[\"SNR\"][:]\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOk-lnxv9MRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "H = np.sqrt(H[:,:,:,0]**2 + H[:,:,:,1]**2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a65Bmt0K2Yxy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "18a1e3f3-1562-4980-a390-190fc09b98d8"
      },
      "source": [
        "H.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4979, 56, 924)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ8l7worP6Mg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "50f39c08-25f3-496c-e0cf-c9380bb88ba8"
      },
      "source": [
        "from sklearn.decomposition import IncrementalPCA\n",
        "\n",
        "pca = IncrementalPCA(66)\n",
        "for i in range(56):\n",
        "  pca.partial_fit(X[:,i,:])\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS5tu6zAQbaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "H2 = np.zeros((H.shape[0],H.shape[1],66))\n",
        "for i in range(56):\n",
        "  H2[:,i,:] = pca.transform(H[:,i,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3qFGewiQsxz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9dc9617f-6e3c-4f81-aef1-d1088f6ad938"
      },
      "source": [
        "print(H2.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4979, 56, 66)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U4rJbdh9nKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "H_Train, H_Test , Pos_Train , Pos_Test = train_test_split(H2,Pos,test_size=0.05, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iwHJXGZRxsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "H_Train = H_Train.reshape(-1,56,66,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL0Lzaf2SQRJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c553035a-5e67-4812-c08e-c842247f19a6"
      },
      "source": [
        "H_Train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4730, 56, 66, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XgoMff4RO8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import Model,Sequential , load_model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense , Dropout, Conv2D ,Flatten\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "def classifier():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(3,(5,5),input_shape=(56,66,1),activation = 'relu' ))\n",
        "    model.add(Conv2D(6,(5,5),activation = 'relu' ))\n",
        "    model.add(Conv2D(8,(5,5),activation = 'relu' ))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(8192 ,activation = 'relu' ))\n",
        "    model.add(Dense(4096 ,activation = 'relu' ))\n",
        "    model.add(Dense(3072 ,activation = 'relu' ))\n",
        "    model.add(Dense(2048 ,activation = 'relu' ))\n",
        "    model.add(Dense(1024 ,activation = 'relu' ))\n",
        "    model.add(Dense(512 ,activation = 'relu' ))\n",
        "    model.add(Dense(128 ,activation = 'relu' ))\n",
        "    model.add(Dense(32 ,activation = 'relu' ))\n",
        "    model.add(Dense(8 ,activation = 'relu' ))\n",
        "    model.add(Dense(3))\n",
        "    model.compile(loss='mean_squared_error', optimizer = Adam(1e-3)) \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpMInbJmRou1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f9739ddd-172e-45d6-c9bb-5d63d5729cef"
      },
      "source": [
        "model = classifier()\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "earlystopper = EarlyStopping(patience = 80, verbose=1)\n",
        "checkpointer = ModelCheckpoint('best_PCA3.h5', verbose=1, save_best_only=True)\n",
        "hist = model.fit(H_Train,Pos_Train , epochs=1000, validation_split=0.1  ,callbacks=[earlystopper, checkpointer],batch_size=4)\n",
        "val_loss = hist.history['val_loss']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 41779.7344\n",
            "Epoch 00001: val_loss improved from inf to 24933.27148, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 56s 53ms/step - loss: 41779.7344 - val_loss: 24933.2715\n",
            "Epoch 2/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 25818.7578\n",
            "Epoch 00002: val_loss did not improve from 24933.27148\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 25818.7578 - val_loss: 25393.3477\n",
            "Epoch 3/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 25700.9395\n",
            "Epoch 00003: val_loss improved from 24933.27148 to 24351.83789, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 53s 50ms/step - loss: 25705.9082 - val_loss: 24351.8379\n",
            "Epoch 4/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 25474.1367\n",
            "Epoch 00004: val_loss improved from 24351.83789 to 23891.80273, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 62s 58ms/step - loss: 25459.5332 - val_loss: 23891.8027\n",
            "Epoch 5/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 25464.4043\n",
            "Epoch 00005: val_loss did not improve from 23891.80273\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 25454.0332 - val_loss: 23950.1719\n",
            "Epoch 6/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 25313.5605\n",
            "Epoch 00006: val_loss did not improve from 23891.80273\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 25313.0801 - val_loss: 25785.9453\n",
            "Epoch 7/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 25311.5273\n",
            "Epoch 00007: val_loss improved from 23891.80273 to 23635.45703, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 56s 52ms/step - loss: 25313.8457 - val_loss: 23635.4570\n",
            "Epoch 8/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 25256.8223\n",
            "Epoch 00008: val_loss did not improve from 23635.45703\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 25269.8730 - val_loss: 24183.8828\n",
            "Epoch 9/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 25219.5059\n",
            "Epoch 00009: val_loss did not improve from 23635.45703\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 25218.3398 - val_loss: 24042.3438\n",
            "Epoch 10/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 25205.3008\n",
            "Epoch 00010: val_loss did not improve from 23635.45703\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 25190.5703 - val_loss: 23652.1895\n",
            "Epoch 11/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 25184.6191\n",
            "Epoch 00011: val_loss improved from 23635.45703 to 23613.30078, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 53s 50ms/step - loss: 25186.6816 - val_loss: 23613.3008\n",
            "Epoch 12/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 25139.9062\n",
            "Epoch 00012: val_loss did not improve from 23613.30078\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 25154.1406 - val_loss: 23715.8984\n",
            "Epoch 13/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 25086.3066\n",
            "Epoch 00013: val_loss did not improve from 23613.30078\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 25075.5410 - val_loss: 23954.3086\n",
            "Epoch 14/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 25120.9609\n",
            "Epoch 00014: val_loss improved from 23613.30078 to 23471.88281, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 55s 52ms/step - loss: 25111.8125 - val_loss: 23471.8828\n",
            "Epoch 15/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 25043.2520\n",
            "Epoch 00015: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 25063.1211 - val_loss: 23677.6992\n",
            "Epoch 16/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 25059.3105\n",
            "Epoch 00016: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 25069.6504 - val_loss: 23564.4688\n",
            "Epoch 17/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 25092.5957\n",
            "Epoch 00017: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 25075.6895 - val_loss: 24118.8691\n",
            "Epoch 18/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 25099.7832\n",
            "Epoch 00018: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 23ms/step - loss: 25079.2891 - val_loss: 24093.8164\n",
            "Epoch 19/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 25040.7656\n",
            "Epoch 00019: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 25044.6523 - val_loss: 24068.1133\n",
            "Epoch 20/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 25042.5684\n",
            "Epoch 00020: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 25037.6914 - val_loss: 23530.8613\n",
            "Epoch 21/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 25001.1855\n",
            "Epoch 00021: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 25016.1113 - val_loss: 23731.9785\n",
            "Epoch 22/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 25025.9336\n",
            "Epoch 00022: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 25004.4863 - val_loss: 23666.2324\n",
            "Epoch 23/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 25029.7891\n",
            "Epoch 00023: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 25023.6523 - val_loss: 23920.2773\n",
            "Epoch 24/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24980.2109\n",
            "Epoch 00024: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24965.8203 - val_loss: 23542.8438\n",
            "Epoch 25/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24989.1699\n",
            "Epoch 00025: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24973.5195 - val_loss: 23858.1934\n",
            "Epoch 26/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24979.0742\n",
            "Epoch 00026: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24967.5957 - val_loss: 23679.4688\n",
            "Epoch 27/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 24949.4043\n",
            "Epoch 00027: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24949.4043 - val_loss: 23836.5918\n",
            "Epoch 28/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24974.5625\n",
            "Epoch 00028: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24970.1797 - val_loss: 23566.3750\n",
            "Epoch 29/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24934.9355\n",
            "Epoch 00029: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24926.8887 - val_loss: 23505.3047\n",
            "Epoch 30/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24938.9473\n",
            "Epoch 00030: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24948.9531 - val_loss: 23613.9004\n",
            "Epoch 31/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 24954.9082\n",
            "Epoch 00031: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 23ms/step - loss: 24954.9082 - val_loss: 23691.5645\n",
            "Epoch 32/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24910.5020\n",
            "Epoch 00032: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24916.1797 - val_loss: 23958.2832\n",
            "Epoch 33/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24918.0762\n",
            "Epoch 00033: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24938.0586 - val_loss: 23889.3418\n",
            "Epoch 34/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24894.3770\n",
            "Epoch 00034: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24922.3789 - val_loss: 23654.7969\n",
            "Epoch 35/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24943.0410\n",
            "Epoch 00035: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24923.7109 - val_loss: 23541.2637\n",
            "Epoch 36/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24889.7441\n",
            "Epoch 00036: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24897.7969 - val_loss: 23768.3652\n",
            "Epoch 37/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 24906.5332\n",
            "Epoch 00037: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24906.5332 - val_loss: 23627.5605\n",
            "Epoch 38/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24922.9824\n",
            "Epoch 00038: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24904.3008 - val_loss: 24070.8867\n",
            "Epoch 39/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24913.5000\n",
            "Epoch 00039: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24925.1738 - val_loss: 23752.5938\n",
            "Epoch 40/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24885.8398\n",
            "Epoch 00040: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24884.2598 - val_loss: 23667.9238\n",
            "Epoch 41/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24839.8965\n",
            "Epoch 00041: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24868.5547 - val_loss: 23844.9531\n",
            "Epoch 42/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24872.0645\n",
            "Epoch 00042: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24885.7832 - val_loss: 23935.7715\n",
            "Epoch 43/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24858.0430\n",
            "Epoch 00043: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24856.4219 - val_loss: 23688.9668\n",
            "Epoch 44/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24870.7246\n",
            "Epoch 00044: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 23ms/step - loss: 24868.0508 - val_loss: 23636.9668\n",
            "Epoch 45/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24874.4492\n",
            "Epoch 00045: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24875.3613 - val_loss: 23846.4648\n",
            "Epoch 46/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24870.1484\n",
            "Epoch 00046: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24867.8457 - val_loss: 23763.9062\n",
            "Epoch 47/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 24864.3242\n",
            "Epoch 00047: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24864.3242 - val_loss: 23613.3047\n",
            "Epoch 48/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24845.2539\n",
            "Epoch 00048: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24859.3867 - val_loss: 23886.8066\n",
            "Epoch 49/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24850.2812\n",
            "Epoch 00049: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24850.8184 - val_loss: 23577.1895\n",
            "Epoch 50/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24839.8574\n",
            "Epoch 00050: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24834.2168 - val_loss: 23905.4863\n",
            "Epoch 51/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24830.2012\n",
            "Epoch 00051: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24827.0781 - val_loss: 23613.3418\n",
            "Epoch 52/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24812.6367\n",
            "Epoch 00052: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24826.4746 - val_loss: 23809.9043\n",
            "Epoch 53/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24828.1113\n",
            "Epoch 00053: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24826.4805 - val_loss: 23564.3555\n",
            "Epoch 54/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24826.0117\n",
            "Epoch 00054: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24826.4668 - val_loss: 23793.0293\n",
            "Epoch 55/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24820.2188\n",
            "Epoch 00055: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24817.9629 - val_loss: 23754.4062\n",
            "Epoch 56/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24838.2012\n",
            "Epoch 00056: val_loss did not improve from 23471.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24829.1777 - val_loss: 23622.5098\n",
            "Epoch 57/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 24783.0742\n",
            "Epoch 00057: val_loss improved from 23471.88281 to 23469.94922, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 51s 48ms/step - loss: 24783.0742 - val_loss: 23469.9492\n",
            "Epoch 58/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24790.0547\n",
            "Epoch 00058: val_loss did not improve from 23469.94922\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24766.2285 - val_loss: 23914.1309\n",
            "Epoch 59/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24772.4258\n",
            "Epoch 00059: val_loss did not improve from 23469.94922\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24765.1562 - val_loss: 23608.6875\n",
            "Epoch 60/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24728.2031\n",
            "Epoch 00060: val_loss did not improve from 23469.94922\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24726.6992 - val_loss: 23601.3867\n",
            "Epoch 61/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 24716.9473\n",
            "Epoch 00061: val_loss improved from 23469.94922 to 23467.71680, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 53s 50ms/step - loss: 24716.9473 - val_loss: 23467.7168\n",
            "Epoch 62/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24629.8789\n",
            "Epoch 00062: val_loss did not improve from 23467.71680\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24670.6367 - val_loss: 23729.2480\n",
            "Epoch 63/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24567.8730\n",
            "Epoch 00063: val_loss improved from 23467.71680 to 23322.75977, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 54s 51ms/step - loss: 24561.0684 - val_loss: 23322.7598\n",
            "Epoch 64/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24451.2559\n",
            "Epoch 00064: val_loss improved from 23322.75977 to 23258.19531, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 63s 60ms/step - loss: 24445.9668 - val_loss: 23258.1953\n",
            "Epoch 65/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 24103.1465\n",
            "Epoch 00065: val_loss improved from 23258.19531 to 23235.03320, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 60s 56ms/step - loss: 24103.1465 - val_loss: 23235.0332\n",
            "Epoch 66/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 22659.6523\n",
            "Epoch 00066: val_loss improved from 23235.03320 to 20340.38867, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 68s 64ms/step - loss: 22648.0098 - val_loss: 20340.3887\n",
            "Epoch 67/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 16148.0098\n",
            "Epoch 00067: val_loss improved from 20340.38867 to 13698.50781, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 65s 61ms/step - loss: 16146.4355 - val_loss: 13698.5078\n",
            "Epoch 68/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 9461.4463\n",
            "Epoch 00068: val_loss improved from 13698.50781 to 10484.56055, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 63s 59ms/step - loss: 9461.9150 - val_loss: 10484.5605\n",
            "Epoch 69/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 6457.0967\n",
            "Epoch 00069: val_loss improved from 10484.56055 to 9286.05566, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 62s 58ms/step - loss: 6456.0801 - val_loss: 9286.0557\n",
            "Epoch 70/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 5267.6348\n",
            "Epoch 00070: val_loss improved from 9286.05566 to 9194.98926, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 62s 59ms/step - loss: 5278.7607 - val_loss: 9194.9893\n",
            "Epoch 71/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 4671.4058\n",
            "Epoch 00071: val_loss did not improve from 9194.98926\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 4670.9595 - val_loss: 9445.7520\n",
            "Epoch 72/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 4375.3789\n",
            "Epoch 00072: val_loss did not improve from 9194.98926\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 4375.3789 - val_loss: 9588.8535\n",
            "Epoch 73/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 4179.6294\n",
            "Epoch 00073: val_loss did not improve from 9194.98926\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 4178.6841 - val_loss: 9737.8408\n",
            "Epoch 74/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 4089.8975\n",
            "Epoch 00074: val_loss did not improve from 9194.98926\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 4087.8042 - val_loss: 9670.9482\n",
            "Epoch 75/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 3889.1594\n",
            "Epoch 00075: val_loss did not improve from 9194.98926\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 3889.7078 - val_loss: 9592.7070\n",
            "Epoch 76/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 3889.8081\n",
            "Epoch 00076: val_loss improved from 9194.98926 to 8840.45410, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 56s 52ms/step - loss: 3890.4104 - val_loss: 8840.4541\n",
            "Epoch 77/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 3863.8105\n",
            "Epoch 00077: val_loss did not improve from 8840.45410\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 3864.2798 - val_loss: 9636.7734\n",
            "Epoch 78/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 3775.3560\n",
            "Epoch 00078: val_loss did not improve from 8840.45410\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 3774.5137 - val_loss: 8958.4561\n",
            "Epoch 79/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 3769.8884\n",
            "Epoch 00079: val_loss did not improve from 8840.45410\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 3771.6050 - val_loss: 9712.4990\n",
            "Epoch 80/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 3696.1130\n",
            "Epoch 00080: val_loss did not improve from 8840.45410\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 3697.9124 - val_loss: 8899.6523\n",
            "Epoch 81/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 3790.6855\n",
            "Epoch 00081: val_loss did not improve from 8840.45410\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 3788.9641 - val_loss: 10191.1514\n",
            "Epoch 82/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 3618.5403\n",
            "Epoch 00082: val_loss did not improve from 8840.45410\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 3620.0476 - val_loss: 9183.5225\n",
            "Epoch 83/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 3553.4114\n",
            "Epoch 00083: val_loss did not improve from 8840.45410\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 3554.9731 - val_loss: 8894.9619\n",
            "Epoch 84/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 3525.1489\n",
            "Epoch 00084: val_loss did not improve from 8840.45410\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 3524.4248 - val_loss: 9055.7207\n",
            "Epoch 85/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 3516.7686\n",
            "Epoch 00085: val_loss did not improve from 8840.45410\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 3516.7686 - val_loss: 8965.1650\n",
            "Epoch 86/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 3528.4280\n",
            "Epoch 00086: val_loss did not improve from 8840.45410\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 3525.8352 - val_loss: 9015.6689\n",
            "Epoch 87/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 3460.4438\n",
            "Epoch 00087: val_loss improved from 8840.45410 to 8797.49414, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 55s 52ms/step - loss: 3461.0637 - val_loss: 8797.4941\n",
            "Epoch 88/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 3402.5383\n",
            "Epoch 00088: val_loss did not improve from 8797.49414\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 3402.9082 - val_loss: 8853.8828\n",
            "Epoch 89/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 3422.3843\n",
            "Epoch 00089: val_loss improved from 8797.49414 to 8788.34961, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 58s 54ms/step - loss: 3422.3843 - val_loss: 8788.3496\n",
            "Epoch 90/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 3374.0432\n",
            "Epoch 00090: val_loss did not improve from 8788.34961\n",
            "1065/1065 [==============================] - 24s 23ms/step - loss: 3371.7783 - val_loss: 9198.4375\n",
            "Epoch 91/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 3249.1177\n",
            "Epoch 00091: val_loss improved from 8788.34961 to 8563.86523, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 52s 49ms/step - loss: 3250.5293 - val_loss: 8563.8652\n",
            "Epoch 92/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 3175.0037\n",
            "Epoch 00092: val_loss improved from 8563.86523 to 8494.62109, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 70s 66ms/step - loss: 3175.0037 - val_loss: 8494.6211\n",
            "Epoch 93/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 3058.5571\n",
            "Epoch 00093: val_loss did not improve from 8494.62109\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 3058.6863 - val_loss: 8911.8418\n",
            "Epoch 94/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 2996.9639\n",
            "Epoch 00094: val_loss did not improve from 8494.62109\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 2999.2458 - val_loss: 8927.0303\n",
            "Epoch 95/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 2844.4309\n",
            "Epoch 00095: val_loss improved from 8494.62109 to 8365.06250, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 61s 57ms/step - loss: 2844.4309 - val_loss: 8365.0625\n",
            "Epoch 96/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 2485.9990\n",
            "Epoch 00096: val_loss did not improve from 8365.06250\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 2484.5583 - val_loss: 8761.7920\n",
            "Epoch 97/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 2172.0808\n",
            "Epoch 00097: val_loss improved from 8365.06250 to 8126.92529, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 57s 53ms/step - loss: 2170.9966 - val_loss: 8126.9253\n",
            "Epoch 98/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 2227.1326\n",
            "Epoch 00098: val_loss improved from 8126.92529 to 7761.68164, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 67s 63ms/step - loss: 2224.9514 - val_loss: 7761.6816\n",
            "Epoch 99/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 1830.8488\n",
            "Epoch 00099: val_loss improved from 7761.68164 to 7435.88281, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 62s 58ms/step - loss: 1831.4874 - val_loss: 7435.8828\n",
            "Epoch 100/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 1634.9603\n",
            "Epoch 00100: val_loss did not improve from 7435.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 1633.6976 - val_loss: 7600.6162\n",
            "Epoch 101/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 1566.3247\n",
            "Epoch 00101: val_loss did not improve from 7435.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 1566.1372 - val_loss: 7896.2910\n",
            "Epoch 102/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 1546.7281\n",
            "Epoch 00102: val_loss did not improve from 7435.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 1545.5078 - val_loss: 8426.6875\n",
            "Epoch 103/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 1630.4386\n",
            "Epoch 00103: val_loss did not improve from 7435.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 1630.4386 - val_loss: 7891.7515\n",
            "Epoch 104/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 1512.3870\n",
            "Epoch 00104: val_loss did not improve from 7435.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 1513.5062 - val_loss: 7811.9204\n",
            "Epoch 105/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 1504.8541\n",
            "Epoch 00105: val_loss did not improve from 7435.88281\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 1503.7656 - val_loss: 7464.9761\n",
            "Epoch 106/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 1846.6121\n",
            "Epoch 00106: val_loss improved from 7435.88281 to 7420.45557, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 61s 57ms/step - loss: 1845.5994 - val_loss: 7420.4556\n",
            "Epoch 107/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 1426.2660\n",
            "Epoch 00107: val_loss did not improve from 7420.45557\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 1426.2660 - val_loss: 7487.0825\n",
            "Epoch 108/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 1366.9500\n",
            "Epoch 00108: val_loss did not improve from 7420.45557\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 1367.2540 - val_loss: 7471.6934\n",
            "Epoch 109/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 1348.2468\n",
            "Epoch 00109: val_loss improved from 7420.45557 to 7327.31982, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 60s 56ms/step - loss: 1348.0181 - val_loss: 7327.3198\n",
            "Epoch 110/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 1403.0450\n",
            "Epoch 00110: val_loss did not improve from 7327.31982\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 1402.6732 - val_loss: 7431.4985\n",
            "Epoch 111/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 1398.7935\n",
            "Epoch 00111: val_loss did not improve from 7327.31982\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 1398.2391 - val_loss: 7424.9702\n",
            "Epoch 112/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 1360.8756\n",
            "Epoch 00112: val_loss did not improve from 7327.31982\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 1363.6748 - val_loss: 7720.0054\n",
            "Epoch 113/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 1343.9128\n",
            "Epoch 00113: val_loss improved from 7327.31982 to 7158.14111, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 55s 52ms/step - loss: 1342.8721 - val_loss: 7158.1411\n",
            "Epoch 114/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 1338.6058\n",
            "Epoch 00114: val_loss did not improve from 7158.14111\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 1339.0432 - val_loss: 7529.7749\n",
            "Epoch 115/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 1453.3848\n",
            "Epoch 00115: val_loss did not improve from 7158.14111\n",
            "1065/1065 [==============================] - 24s 23ms/step - loss: 1452.6515 - val_loss: 7546.4653\n",
            "Epoch 116/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 1308.0171\n",
            "Epoch 00116: val_loss did not improve from 7158.14111\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 1307.0328 - val_loss: 7298.3018\n",
            "Epoch 117/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 1267.0122\n",
            "Epoch 00117: val_loss did not improve from 7158.14111\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 1267.8992 - val_loss: 7447.2729\n",
            "Epoch 118/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 1287.9760\n",
            "Epoch 00118: val_loss did not improve from 7158.14111\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 1289.2197 - val_loss: 7694.5151\n",
            "Epoch 119/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 1231.2429\n",
            "Epoch 00119: val_loss did not improve from 7158.14111\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 1231.2429 - val_loss: 8126.0430\n",
            "Epoch 120/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 1081.6045\n",
            "Epoch 00120: val_loss did not improve from 7158.14111\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 1083.5565 - val_loss: 8182.5298\n",
            "Epoch 121/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 949.5868\n",
            "Epoch 00121: val_loss did not improve from 7158.14111\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 950.3138 - val_loss: 7680.6191\n",
            "Epoch 122/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 865.3310\n",
            "Epoch 00122: val_loss did not improve from 7158.14111\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 864.6193 - val_loss: 7744.2871\n",
            "Epoch 123/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 727.9633\n",
            "Epoch 00123: val_loss did not improve from 7158.14111\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 727.6645 - val_loss: 7828.4531\n",
            "Epoch 124/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 647.8016\n",
            "Epoch 00124: val_loss did not improve from 7158.14111\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 647.8016 - val_loss: 7522.8701\n",
            "Epoch 125/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 673.9360\n",
            "Epoch 00125: val_loss did not improve from 7158.14111\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 673.5973 - val_loss: 7858.9561\n",
            "Epoch 126/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 713.6458\n",
            "Epoch 00126: val_loss did not improve from 7158.14111\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 713.1958 - val_loss: 7623.5967\n",
            "Epoch 127/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 569.2360\n",
            "Epoch 00127: val_loss did not improve from 7158.14111\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 569.0150 - val_loss: 7429.9932\n",
            "Epoch 128/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 452.5503\n",
            "Epoch 00128: val_loss did not improve from 7158.14111\n",
            "1065/1065 [==============================] - 24s 23ms/step - loss: 452.5900 - val_loss: 7303.1411\n",
            "Epoch 129/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 389.2761\n",
            "Epoch 00129: val_loss did not improve from 7158.14111\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 389.1231 - val_loss: 7574.1729\n",
            "Epoch 130/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 317.8538\n",
            "Epoch 00130: val_loss did not improve from 7158.14111\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 318.0782 - val_loss: 7200.0234\n",
            "Epoch 131/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 292.9489\n",
            "Epoch 00131: val_loss did not improve from 7158.14111\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 292.7556 - val_loss: 7327.7749\n",
            "Epoch 132/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 272.1134\n",
            "Epoch 00132: val_loss did not improve from 7158.14111\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 272.0864 - val_loss: 7904.4692\n",
            "Epoch 133/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 294.4632\n",
            "Epoch 00133: val_loss did not improve from 7158.14111\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 294.2538 - val_loss: 7286.0273\n",
            "Epoch 134/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 290.8332\n",
            "Epoch 00134: val_loss did not improve from 7158.14111\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 291.3339 - val_loss: 7364.4194\n",
            "Epoch 135/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 384.0243\n",
            "Epoch 00135: val_loss did not improve from 7158.14111\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 389.5512 - val_loss: 11334.0898\n",
            "Epoch 136/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 974.2422\n",
            "Epoch 00136: val_loss improved from 7158.14111 to 6785.40820, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 53s 50ms/step - loss: 973.7249 - val_loss: 6785.4082\n",
            "Epoch 137/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 281.7873\n",
            "Epoch 00137: val_loss improved from 6785.40820 to 6706.65967, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 69s 65ms/step - loss: 281.5934 - val_loss: 6706.6597\n",
            "Epoch 138/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 165.1876\n",
            "Epoch 00138: val_loss did not improve from 6706.65967\n",
            "1065/1065 [==============================] - 24s 23ms/step - loss: 165.3164 - val_loss: 6899.3745\n",
            "Epoch 139/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 137.5165\n",
            "Epoch 00139: val_loss did not improve from 6706.65967\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 137.4661 - val_loss: 6964.1899\n",
            "Epoch 140/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 143.5121\n",
            "Epoch 00140: val_loss did not improve from 6706.65967\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 143.4389 - val_loss: 6968.6040\n",
            "Epoch 141/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 176.8050\n",
            "Epoch 00141: val_loss did not improve from 6706.65967\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 176.8050 - val_loss: 7041.5522\n",
            "Epoch 142/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 235.5089\n",
            "Epoch 00142: val_loss did not improve from 6706.65967\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 235.2989 - val_loss: 7075.8794\n",
            "Epoch 143/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 210.0535\n",
            "Epoch 00143: val_loss did not improve from 6706.65967\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 209.8642 - val_loss: 6763.8188\n",
            "Epoch 144/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 339.9396\n",
            "Epoch 00144: val_loss did not improve from 6706.65967\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 339.6921 - val_loss: 6896.1094\n",
            "Epoch 145/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 163.6905\n",
            "Epoch 00145: val_loss did not improve from 6706.65967\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 163.7905 - val_loss: 6898.9287\n",
            "Epoch 146/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 198.7450\n",
            "Epoch 00146: val_loss did not improve from 6706.65967\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 198.7450 - val_loss: 6777.9209\n",
            "Epoch 147/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 190.3519\n",
            "Epoch 00147: val_loss did not improve from 6706.65967\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 190.6668 - val_loss: 7125.1392\n",
            "Epoch 148/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 267.8392\n",
            "Epoch 00148: val_loss did not improve from 6706.65967\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 267.6168 - val_loss: 6768.6455\n",
            "Epoch 149/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 168.2084\n",
            "Epoch 00149: val_loss did not improve from 6706.65967\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 168.3314 - val_loss: 7099.5503\n",
            "Epoch 150/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 132.7533\n",
            "Epoch 00150: val_loss did not improve from 6706.65967\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 132.9596 - val_loss: 6878.5596\n",
            "Epoch 151/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 155.2753\n",
            "Epoch 00151: val_loss did not improve from 6706.65967\n",
            "1065/1065 [==============================] - 24s 23ms/step - loss: 155.2753 - val_loss: 6809.5024\n",
            "Epoch 152/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 164.5052\n",
            "Epoch 00152: val_loss did not improve from 6706.65967\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 164.4289 - val_loss: 6943.2441\n",
            "Epoch 153/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 370.4944\n",
            "Epoch 00153: val_loss did not improve from 6706.65967\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 371.3834 - val_loss: 7488.9868\n",
            "Epoch 154/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 565.8640\n",
            "Epoch 00154: val_loss did not improve from 6706.65967\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 565.3021 - val_loss: 6873.0083\n",
            "Epoch 155/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 177.2085\n",
            "Epoch 00155: val_loss improved from 6706.65967 to 6580.06885, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 59s 55ms/step - loss: 177.1549 - val_loss: 6580.0688\n",
            "Epoch 156/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 108.4418\n",
            "Epoch 00156: val_loss did not improve from 6580.06885\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 108.3760 - val_loss: 6674.3545\n",
            "Epoch 157/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 111.6361\n",
            "Epoch 00157: val_loss did not improve from 6580.06885\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 111.5430 - val_loss: 6907.4277\n",
            "Epoch 158/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 163.7234\n",
            "Epoch 00158: val_loss did not improve from 6580.06885\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 163.8782 - val_loss: 6929.5684\n",
            "Epoch 159/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 143.5592\n",
            "Epoch 00159: val_loss did not improve from 6580.06885\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 143.6173 - val_loss: 6791.1724\n",
            "Epoch 160/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 139.7220\n",
            "Epoch 00160: val_loss did not improve from 6580.06885\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 139.7220 - val_loss: 6869.3774\n",
            "Epoch 161/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 272.7038\n",
            "Epoch 00161: val_loss did not improve from 6580.06885\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 272.8430 - val_loss: 7241.9180\n",
            "Epoch 162/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 166.2916\n",
            "Epoch 00162: val_loss did not improve from 6580.06885\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 166.2045 - val_loss: 6681.6416\n",
            "Epoch 163/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 157.1019\n",
            "Epoch 00163: val_loss did not improve from 6580.06885\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 157.4376 - val_loss: 6953.1621\n",
            "Epoch 164/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 213.4474\n",
            "Epoch 00164: val_loss improved from 6580.06885 to 6473.43652, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 59s 55ms/step - loss: 213.2932 - val_loss: 6473.4365\n",
            "Epoch 165/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 112.9972\n",
            "Epoch 00165: val_loss did not improve from 6473.43652\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 112.9680 - val_loss: 6546.2930\n",
            "Epoch 166/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 98.9234\n",
            "Epoch 00166: val_loss did not improve from 6473.43652\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 98.9349 - val_loss: 6655.3838\n",
            "Epoch 167/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 121.7273\n",
            "Epoch 00167: val_loss did not improve from 6473.43652\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 121.6927 - val_loss: 6551.4600\n",
            "Epoch 168/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 132.0240\n",
            "Epoch 00168: val_loss did not improve from 6473.43652\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 132.1435 - val_loss: 6601.2871\n",
            "Epoch 169/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 156.1161\n",
            "Epoch 00169: val_loss did not improve from 6473.43652\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 156.1161 - val_loss: 6802.4883\n",
            "Epoch 170/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 153.6100\n",
            "Epoch 00170: val_loss did not improve from 6473.43652\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 153.5301 - val_loss: 6512.7134\n",
            "Epoch 171/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 126.4447\n",
            "Epoch 00171: val_loss did not improve from 6473.43652\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 126.3179 - val_loss: 6627.6655\n",
            "Epoch 172/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 156.6054\n",
            "Epoch 00172: val_loss did not improve from 6473.43652\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 156.7688 - val_loss: 7251.1611\n",
            "Epoch 173/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 187.0319\n",
            "Epoch 00173: val_loss did not improve from 6473.43652\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 186.9108 - val_loss: 6593.3071\n",
            "Epoch 174/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 114.4812\n",
            "Epoch 00174: val_loss did not improve from 6473.43652\n",
            "1065/1065 [==============================] - 24s 23ms/step - loss: 114.4812 - val_loss: 6545.9756\n",
            "Epoch 175/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 97.2490\n",
            "Epoch 00175: val_loss did not improve from 6473.43652\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 97.1544 - val_loss: 6714.4717\n",
            "Epoch 176/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 100.7336\n",
            "Epoch 00176: val_loss did not improve from 6473.43652\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 100.6635 - val_loss: 6627.5869\n",
            "Epoch 177/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 162.0643\n",
            "Epoch 00177: val_loss did not improve from 6473.43652\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 162.3477 - val_loss: 6591.7778\n",
            "Epoch 178/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 237.4977\n",
            "Epoch 00178: val_loss did not improve from 6473.43652\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 237.3268 - val_loss: 6976.0815\n",
            "Epoch 179/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 117.7880\n",
            "Epoch 00179: val_loss did not improve from 6473.43652\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 117.7880 - val_loss: 6805.0527\n",
            "Epoch 180/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 101.5068\n",
            "Epoch 00180: val_loss improved from 6473.43652 to 6449.71826, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 59s 55ms/step - loss: 101.4772 - val_loss: 6449.7183\n",
            "Epoch 181/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 118.9884\n",
            "Epoch 00181: val_loss did not improve from 6449.71826\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 118.8926 - val_loss: 6908.1924\n",
            "Epoch 182/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 1106.6244\n",
            "Epoch 00182: val_loss did not improve from 6449.71826\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 1106.6244 - val_loss: 6959.6538\n",
            "Epoch 183/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 165.3675\n",
            "Epoch 00183: val_loss did not improve from 6449.71826\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 165.3504 - val_loss: 6882.9248\n",
            "Epoch 184/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 78.6619\n",
            "Epoch 00184: val_loss did not improve from 6449.71826\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 78.6593 - val_loss: 7082.9897\n",
            "Epoch 185/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 74.8281\n",
            "Epoch 00185: val_loss did not improve from 6449.71826\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 74.7762 - val_loss: 6834.9956\n",
            "Epoch 186/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 90.4050\n",
            "Epoch 00186: val_loss did not improve from 6449.71826\n",
            "1065/1065 [==============================] - 24s 23ms/step - loss: 90.3906 - val_loss: 6711.7505\n",
            "Epoch 187/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 218.7126\n",
            "Epoch 00187: val_loss did not improve from 6449.71826\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 218.7126 - val_loss: 6976.9717\n",
            "Epoch 188/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 135.9258\n",
            "Epoch 00188: val_loss did not improve from 6449.71826\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 135.8610 - val_loss: 6802.3867\n",
            "Epoch 189/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 98.5366\n",
            "Epoch 00189: val_loss did not improve from 6449.71826\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 98.4984 - val_loss: 6991.0200\n",
            "Epoch 190/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 1131.0781\n",
            "Epoch 00190: val_loss did not improve from 6449.71826\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 1130.2910 - val_loss: 7211.0410\n",
            "Epoch 191/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 321.6459\n",
            "Epoch 00191: val_loss did not improve from 6449.71826\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 321.5268 - val_loss: 7117.9907\n",
            "Epoch 192/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 8692.6758\n",
            "Epoch 00192: val_loss did not improve from 6449.71826\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 8692.6758 - val_loss: 6550.8730\n",
            "Epoch 193/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 690.4040\n",
            "Epoch 00193: val_loss improved from 6449.71826 to 6418.04736, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 60s 56ms/step - loss: 690.2528 - val_loss: 6418.0474\n",
            "Epoch 194/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 292.3947\n",
            "Epoch 00194: val_loss did not improve from 6418.04736\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 292.1516 - val_loss: 6419.7720\n",
            "Epoch 195/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 169.2892\n",
            "Epoch 00195: val_loss did not improve from 6418.04736\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 169.2976 - val_loss: 6598.4502\n",
            "Epoch 196/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 118.3330\n",
            "Epoch 00196: val_loss did not improve from 6418.04736\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 118.3330 - val_loss: 6694.2139\n",
            "Epoch 197/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 109.9356\n",
            "Epoch 00197: val_loss did not improve from 6418.04736\n",
            "1065/1065 [==============================] - 24s 23ms/step - loss: 109.9602 - val_loss: 6733.2305\n",
            "Epoch 198/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 136.5582\n",
            "Epoch 00198: val_loss did not improve from 6418.04736\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 136.5091 - val_loss: 6945.6079\n",
            "Epoch 199/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 137.4281\n",
            "Epoch 00199: val_loss did not improve from 6418.04736\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 137.4462 - val_loss: 6857.8032\n",
            "Epoch 200/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 110.4499\n",
            "Epoch 00200: val_loss improved from 6418.04736 to 6348.74365, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 55s 52ms/step - loss: 110.5062 - val_loss: 6348.7437\n",
            "Epoch 201/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 104.9463\n",
            "Epoch 00201: val_loss did not improve from 6348.74365\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 105.0128 - val_loss: 6730.6475\n",
            "Epoch 202/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 119.4984\n",
            "Epoch 00202: val_loss did not improve from 6348.74365\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 119.4527 - val_loss: 6739.2100\n",
            "Epoch 203/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 114.2971\n",
            "Epoch 00203: val_loss did not improve from 6348.74365\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 114.2779 - val_loss: 6566.2998\n",
            "Epoch 204/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 118.7621\n",
            "Epoch 00204: val_loss did not improve from 6348.74365\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 118.7097 - val_loss: 6597.2998\n",
            "Epoch 205/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 107.0658\n",
            "Epoch 00205: val_loss did not improve from 6348.74365\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 107.0187 - val_loss: 6435.9434\n",
            "Epoch 206/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 130.2920\n",
            "Epoch 00206: val_loss improved from 6348.74365 to 6330.71826, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 60s 56ms/step - loss: 130.2453 - val_loss: 6330.7183\n",
            "Epoch 207/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 116.7159\n",
            "Epoch 00207: val_loss did not improve from 6330.71826\n",
            "1065/1065 [==============================] - 24s 23ms/step - loss: 116.8399 - val_loss: 6565.8564\n",
            "Epoch 208/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 97.4708\n",
            "Epoch 00208: val_loss did not improve from 6330.71826\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 97.4708 - val_loss: 6531.3472\n",
            "Epoch 209/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 89.7787\n",
            "Epoch 00209: val_loss did not improve from 6330.71826\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 89.7116 - val_loss: 6446.7124\n",
            "Epoch 210/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 88.9235\n",
            "Epoch 00210: val_loss did not improve from 6330.71826\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 88.8837 - val_loss: 6644.8154\n",
            "Epoch 211/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 99.3960\n",
            "Epoch 00211: val_loss did not improve from 6330.71826\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 99.4118 - val_loss: 6627.9810\n",
            "Epoch 212/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 97.3721\n",
            "Epoch 00212: val_loss did not improve from 6330.71826\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 97.3296 - val_loss: 6617.9653\n",
            "Epoch 213/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 117.7981\n",
            "Epoch 00213: val_loss did not improve from 6330.71826\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 117.7981 - val_loss: 6458.0596\n",
            "Epoch 214/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 92.0160\n",
            "Epoch 00214: val_loss did not improve from 6330.71826\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 92.0424 - val_loss: 6418.7104\n",
            "Epoch 215/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 77.4213\n",
            "Epoch 00215: val_loss did not improve from 6330.71826\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 77.4043 - val_loss: 6498.0615\n",
            "Epoch 216/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 78.4113\n",
            "Epoch 00216: val_loss did not improve from 6330.71826\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 78.3490 - val_loss: 6470.3457\n",
            "Epoch 217/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 102.0255\n",
            "Epoch 00217: val_loss improved from 6330.71826 to 6314.51562, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 60s 57ms/step - loss: 102.0255 - val_loss: 6314.5156\n",
            "Epoch 218/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 106.0855\n",
            "Epoch 00218: val_loss did not improve from 6314.51562\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 106.0788 - val_loss: 6544.2446\n",
            "Epoch 219/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 85.2039\n",
            "Epoch 00219: val_loss improved from 6314.51562 to 6208.34717, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 60s 56ms/step - loss: 85.1632 - val_loss: 6208.3472\n",
            "Epoch 220/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 72.3108\n",
            "Epoch 00220: val_loss did not improve from 6208.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 72.3108 - val_loss: 6558.1235\n",
            "Epoch 221/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 70.2813\n",
            "Epoch 00221: val_loss did not improve from 6208.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 70.2947 - val_loss: 6293.1885\n",
            "Epoch 222/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 83.7436\n",
            "Epoch 00222: val_loss did not improve from 6208.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 83.7380 - val_loss: 6388.3516\n",
            "Epoch 223/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 76.9603\n",
            "Epoch 00223: val_loss did not improve from 6208.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 76.9467 - val_loss: 6278.2666\n",
            "Epoch 224/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 75.6024\n",
            "Epoch 00224: val_loss did not improve from 6208.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 75.5951 - val_loss: 6318.1538\n",
            "Epoch 225/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 88.4114\n",
            "Epoch 00225: val_loss did not improve from 6208.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 88.3585 - val_loss: 6825.6797\n",
            "Epoch 226/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 73.6142\n",
            "Epoch 00226: val_loss did not improve from 6208.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 73.5640 - val_loss: 6277.2896\n",
            "Epoch 227/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 73.3808\n",
            "Epoch 00227: val_loss did not improve from 6208.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 73.4077 - val_loss: 6230.1963\n",
            "Epoch 228/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 94.2023\n",
            "Epoch 00228: val_loss did not improve from 6208.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 94.2023 - val_loss: 6377.7822\n",
            "Epoch 229/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 82.2941\n",
            "Epoch 00229: val_loss did not improve from 6208.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 82.2548 - val_loss: 6400.4092\n",
            "Epoch 230/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 68.4588\n",
            "Epoch 00230: val_loss improved from 6208.34717 to 6125.74219, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 59s 56ms/step - loss: 68.4907 - val_loss: 6125.7422\n",
            "Epoch 231/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 71.1335\n",
            "Epoch 00231: val_loss did not improve from 6125.74219\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 71.1180 - val_loss: 6432.4888\n",
            "Epoch 232/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 69.9394\n",
            "Epoch 00232: val_loss did not improve from 6125.74219\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 70.0235 - val_loss: 6473.0000\n",
            "Epoch 233/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 75.7373\n",
            "Epoch 00233: val_loss did not improve from 6125.74219\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 75.6958 - val_loss: 6529.0361\n",
            "Epoch 234/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 69.9935\n",
            "Epoch 00234: val_loss did not improve from 6125.74219\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 69.9935 - val_loss: 6469.8726\n",
            "Epoch 235/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 66.7898\n",
            "Epoch 00235: val_loss did not improve from 6125.74219\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 66.7441 - val_loss: 6333.2671\n",
            "Epoch 236/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 68.6054\n",
            "Epoch 00236: val_loss did not improve from 6125.74219\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 68.6054 - val_loss: 6272.6240\n",
            "Epoch 237/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 62.8119\n",
            "Epoch 00237: val_loss did not improve from 6125.74219\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 62.8018 - val_loss: 6278.1040\n",
            "Epoch 238/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 63.5396\n",
            "Epoch 00238: val_loss did not improve from 6125.74219\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 63.5454 - val_loss: 6217.2812\n",
            "Epoch 239/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 68.3120\n",
            "Epoch 00239: val_loss did not improve from 6125.74219\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 68.3120 - val_loss: 6234.3765\n",
            "Epoch 240/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 65.1297\n",
            "Epoch 00240: val_loss did not improve from 6125.74219\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 65.0853 - val_loss: 6279.6494\n",
            "Epoch 241/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 77.6054\n",
            "Epoch 00241: val_loss did not improve from 6125.74219\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 77.5799 - val_loss: 6295.7490\n",
            "Epoch 242/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 63.0552\n",
            "Epoch 00242: val_loss did not improve from 6125.74219\n",
            "1065/1065 [==============================] - 24s 23ms/step - loss: 63.1159 - val_loss: 6167.8247\n",
            "Epoch 243/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 59.6307\n",
            "Epoch 00243: val_loss did not improve from 6125.74219\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 59.6033 - val_loss: 6342.1968\n",
            "Epoch 244/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 73.8409\n",
            "Epoch 00244: val_loss did not improve from 6125.74219\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 73.8409 - val_loss: 6143.3628\n",
            "Epoch 245/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 77.7299\n",
            "Epoch 00245: val_loss improved from 6125.74219 to 6112.17676, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 60s 57ms/step - loss: 77.7095 - val_loss: 6112.1768\n",
            "Epoch 246/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 61.1306\n",
            "Epoch 00246: val_loss did not improve from 6112.17676\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 61.0982 - val_loss: 6260.3184\n",
            "Epoch 247/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 66.4858\n",
            "Epoch 00247: val_loss did not improve from 6112.17676\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 66.4335 - val_loss: 6179.2900\n",
            "Epoch 248/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 60.2111\n",
            "Epoch 00248: val_loss did not improve from 6112.17676\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 60.1815 - val_loss: 6154.0645\n",
            "Epoch 249/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 76.1804\n",
            "Epoch 00249: val_loss did not improve from 6112.17676\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 76.1148 - val_loss: 6260.9312\n",
            "Epoch 250/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 68.5719\n",
            "Epoch 00250: val_loss did not improve from 6112.17676\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 68.5189 - val_loss: 6218.2998\n",
            "Epoch 251/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 70.5168\n",
            "Epoch 00251: val_loss did not improve from 6112.17676\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 70.4933 - val_loss: 6116.4878\n",
            "Epoch 252/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 59.4121\n",
            "Epoch 00252: val_loss improved from 6112.17676 to 6020.64258, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 60s 56ms/step - loss: 59.4121 - val_loss: 6020.6426\n",
            "Epoch 253/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 62.1917\n",
            "Epoch 00253: val_loss did not improve from 6020.64258\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 62.1667 - val_loss: 6124.8228\n",
            "Epoch 254/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 59.7922\n",
            "Epoch 00254: val_loss improved from 6020.64258 to 5795.99463, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 61s 57ms/step - loss: 59.7874 - val_loss: 5795.9946\n",
            "Epoch 255/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 59.2975\n",
            "Epoch 00255: val_loss did not improve from 5795.99463\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 59.2422 - val_loss: 6229.2080\n",
            "Epoch 256/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 65.4199\n",
            "Epoch 00256: val_loss did not improve from 5795.99463\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 65.3939 - val_loss: 6062.7651\n",
            "Epoch 257/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 57.4204\n",
            "Epoch 00257: val_loss did not improve from 5795.99463\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 57.4477 - val_loss: 6103.4502\n",
            "Epoch 258/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 60.3547\n",
            "Epoch 00258: val_loss did not improve from 5795.99463\n",
            "1065/1065 [==============================] - 24s 23ms/step - loss: 60.3719 - val_loss: 6126.9946\n",
            "Epoch 259/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 63.8720\n",
            "Epoch 00259: val_loss did not improve from 5795.99463\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 63.8720 - val_loss: 6118.2861\n",
            "Epoch 260/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 58.6028\n",
            "Epoch 00260: val_loss did not improve from 5795.99463\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 58.6326 - val_loss: 6285.6484\n",
            "Epoch 261/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 58.0175\n",
            "Epoch 00261: val_loss did not improve from 5795.99463\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 58.0253 - val_loss: 6048.6094\n",
            "Epoch 262/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 62.2823\n",
            "Epoch 00262: val_loss did not improve from 5795.99463\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 62.2507 - val_loss: 6102.9204\n",
            "Epoch 263/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 53.9005\n",
            "Epoch 00263: val_loss did not improve from 5795.99463\n",
            "1065/1065 [==============================] - 24s 23ms/step - loss: 53.8774 - val_loss: 6085.4858\n",
            "Epoch 264/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 56.4624\n",
            "Epoch 00264: val_loss did not improve from 5795.99463\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 56.4624 - val_loss: 6049.6055\n",
            "Epoch 265/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 61.2591\n",
            "Epoch 00265: val_loss did not improve from 5795.99463\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 61.2144 - val_loss: 6068.8135\n",
            "Epoch 266/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 57.5681\n",
            "Epoch 00266: val_loss did not improve from 5795.99463\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 57.6079 - val_loss: 6102.7871\n",
            "Epoch 267/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 54.1549\n",
            "Epoch 00267: val_loss did not improve from 5795.99463\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 54.1268 - val_loss: 5928.5771\n",
            "Epoch 268/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 51.9671\n",
            "Epoch 00268: val_loss did not improve from 5795.99463\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 51.9319 - val_loss: 5869.1089\n",
            "Epoch 269/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 57.1470\n",
            "Epoch 00269: val_loss did not improve from 5795.99463\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 57.1092 - val_loss: 5966.8960\n",
            "Epoch 270/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 56.3298\n",
            "Epoch 00270: val_loss did not improve from 5795.99463\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 56.3294 - val_loss: 5892.6040\n",
            "Epoch 271/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 56.5961\n",
            "Epoch 00271: val_loss did not improve from 5795.99463\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 56.6000 - val_loss: 5909.8862\n",
            "Epoch 272/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 52.0985\n",
            "Epoch 00272: val_loss did not improve from 5795.99463\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 52.1338 - val_loss: 5911.4258\n",
            "Epoch 273/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 46.4591\n",
            "Epoch 00273: val_loss did not improve from 5795.99463\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 46.4313 - val_loss: 6030.6455\n",
            "Epoch 274/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 51.1589\n",
            "Epoch 00274: val_loss did not improve from 5795.99463\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 51.1324 - val_loss: 6023.1660\n",
            "Epoch 275/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 61.3536\n",
            "Epoch 00275: val_loss did not improve from 5795.99463\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 61.3172 - val_loss: 6028.8267\n",
            "Epoch 276/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 70.9006\n",
            "Epoch 00276: val_loss did not improve from 5795.99463\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 70.8798 - val_loss: 5819.1992\n",
            "Epoch 277/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 55.3721\n",
            "Epoch 00277: val_loss improved from 5795.99463 to 5746.77393, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 60s 56ms/step - loss: 55.3610 - val_loss: 5746.7739\n",
            "Epoch 278/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 45.1189\n",
            "Epoch 00278: val_loss did not improve from 5746.77393\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 45.1457 - val_loss: 5906.0635\n",
            "Epoch 279/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 40.4677\n",
            "Epoch 00279: val_loss did not improve from 5746.77393\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 40.4602 - val_loss: 5902.9624\n",
            "Epoch 280/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 63.9610\n",
            "Epoch 00280: val_loss did not improve from 5746.77393\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 63.9596 - val_loss: 5802.3188\n",
            "Epoch 281/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 58.1898\n",
            "Epoch 00281: val_loss did not improve from 5746.77393\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 58.1795 - val_loss: 5938.6772\n",
            "Epoch 282/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 45.6977\n",
            "Epoch 00282: val_loss improved from 5746.77393 to 5710.49219, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 60s 56ms/step - loss: 45.7682 - val_loss: 5710.4922\n",
            "Epoch 283/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 47.3924\n",
            "Epoch 00283: val_loss improved from 5710.49219 to 5617.12061, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 61s 57ms/step - loss: 47.4018 - val_loss: 5617.1206\n",
            "Epoch 284/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 51.7344\n",
            "Epoch 00284: val_loss did not improve from 5617.12061\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 51.7102 - val_loss: 5853.3613\n",
            "Epoch 285/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 52.8478\n",
            "Epoch 00285: val_loss did not improve from 5617.12061\n",
            "1065/1065 [==============================] - 24s 23ms/step - loss: 52.8478 - val_loss: 5964.7051\n",
            "Epoch 286/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 51.0157\n",
            "Epoch 00286: val_loss did not improve from 5617.12061\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 50.9939 - val_loss: 5915.0234\n",
            "Epoch 287/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 42.9449\n",
            "Epoch 00287: val_loss did not improve from 5617.12061\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 43.0132 - val_loss: 5877.8076\n",
            "Epoch 288/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 52.6772\n",
            "Epoch 00288: val_loss did not improve from 5617.12061\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 52.7078 - val_loss: 6229.0132\n",
            "Epoch 289/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 52.0996\n",
            "Epoch 00289: val_loss did not improve from 5617.12061\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 52.1132 - val_loss: 6098.6172\n",
            "Epoch 290/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 54.8263\n",
            "Epoch 00290: val_loss did not improve from 5617.12061\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 54.8263 - val_loss: 5808.9683\n",
            "Epoch 291/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 50.0246\n",
            "Epoch 00291: val_loss did not improve from 5617.12061\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 50.0530 - val_loss: 5757.0952\n",
            "Epoch 292/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 51.2097\n",
            "Epoch 00292: val_loss did not improve from 5617.12061\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 51.1658 - val_loss: 5859.8643\n",
            "Epoch 293/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 46.3176\n",
            "Epoch 00293: val_loss did not improve from 5617.12061\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 46.3291 - val_loss: 5718.1851\n",
            "Epoch 294/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 47.1376\n",
            "Epoch 00294: val_loss improved from 5617.12061 to 5560.62451, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 54s 51ms/step - loss: 47.0898 - val_loss: 5560.6245\n",
            "Epoch 295/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 56.9192\n",
            "Epoch 00295: val_loss did not improve from 5560.62451\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 57.0168 - val_loss: 5901.6416\n",
            "Epoch 296/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 48.8488\n",
            "Epoch 00296: val_loss did not improve from 5560.62451\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 48.8488 - val_loss: 6025.3638\n",
            "Epoch 297/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 53.7623\n",
            "Epoch 00297: val_loss did not improve from 5560.62451\n",
            "1065/1065 [==============================] - 24s 23ms/step - loss: 53.7507 - val_loss: 6009.9810\n",
            "Epoch 298/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 45.5557\n",
            "Epoch 00298: val_loss did not improve from 5560.62451\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 45.6119 - val_loss: 5865.6836\n",
            "Epoch 299/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 42.8178\n",
            "Epoch 00299: val_loss did not improve from 5560.62451\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 42.8178 - val_loss: 5946.7695\n",
            "Epoch 300/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 45.8916\n",
            "Epoch 00300: val_loss did not improve from 5560.62451\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 45.8658 - val_loss: 5608.2998\n",
            "Epoch 301/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 53.9558\n",
            "Epoch 00301: val_loss did not improve from 5560.62451\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 53.9398 - val_loss: 5823.1704\n",
            "Epoch 302/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 51.5348\n",
            "Epoch 00302: val_loss did not improve from 5560.62451\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 51.5183 - val_loss: 5600.1240\n",
            "Epoch 303/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 45.5777\n",
            "Epoch 00303: val_loss did not improve from 5560.62451\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 45.5907 - val_loss: 5955.8008\n",
            "Epoch 304/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 44.2972\n",
            "Epoch 00304: val_loss did not improve from 5560.62451\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 44.2972 - val_loss: 5801.3262\n",
            "Epoch 305/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 48.3078\n",
            "Epoch 00305: val_loss did not improve from 5560.62451\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 48.3179 - val_loss: 5902.3584\n",
            "Epoch 306/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 46.1967\n",
            "Epoch 00306: val_loss did not improve from 5560.62451\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 46.1825 - val_loss: 5699.8828\n",
            "Epoch 307/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 47.2411\n",
            "Epoch 00307: val_loss did not improve from 5560.62451\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 47.1993 - val_loss: 5630.3135\n",
            "Epoch 308/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 47.1323\n",
            "Epoch 00308: val_loss did not improve from 5560.62451\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 47.1043 - val_loss: 5660.2407\n",
            "Epoch 309/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 48.7471\n",
            "Epoch 00309: val_loss improved from 5560.62451 to 5539.19971, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 58s 54ms/step - loss: 48.7991 - val_loss: 5539.1997\n",
            "Epoch 310/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 44.5780\n",
            "Epoch 00310: val_loss did not improve from 5539.19971\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 44.5407 - val_loss: 5705.4580\n",
            "Epoch 311/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 44.8685\n",
            "Epoch 00311: val_loss did not improve from 5539.19971\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 44.8762 - val_loss: 5716.2798\n",
            "Epoch 312/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 41.4273\n",
            "Epoch 00312: val_loss did not improve from 5539.19971\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 41.4133 - val_loss: 5950.5083\n",
            "Epoch 313/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 51.4553\n",
            "Epoch 00313: val_loss did not improve from 5539.19971\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 51.4553 - val_loss: 5596.2715\n",
            "Epoch 314/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 45.9033\n",
            "Epoch 00314: val_loss did not improve from 5539.19971\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 45.9062 - val_loss: 5739.1392\n",
            "Epoch 315/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 42.8278\n",
            "Epoch 00315: val_loss did not improve from 5539.19971\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 42.8099 - val_loss: 5659.1738\n",
            "Epoch 316/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 43.1387\n",
            "Epoch 00316: val_loss did not improve from 5539.19971\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 43.1410 - val_loss: 5741.9473\n",
            "Epoch 317/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 51.7346\n",
            "Epoch 00317: val_loss did not improve from 5539.19971\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 51.6978 - val_loss: 5620.0044\n",
            "Epoch 318/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 46.3068\n",
            "Epoch 00318: val_loss did not improve from 5539.19971\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 46.2900 - val_loss: 5779.7383\n",
            "Epoch 319/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 49.0717\n",
            "Epoch 00319: val_loss did not improve from 5539.19971\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 49.0755 - val_loss: 5808.9028\n",
            "Epoch 320/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 43.2050\n",
            "Epoch 00320: val_loss did not improve from 5539.19971\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 43.1756 - val_loss: 5565.4248\n",
            "Epoch 321/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 39.3428\n",
            "Epoch 00321: val_loss did not improve from 5539.19971\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 39.3436 - val_loss: 5703.9033\n",
            "Epoch 322/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 42.5303\n",
            "Epoch 00322: val_loss did not improve from 5539.19971\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 42.5519 - val_loss: 5634.6489\n",
            "Epoch 323/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 37.0255\n",
            "Epoch 00323: val_loss did not improve from 5539.19971\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 37.0255 - val_loss: 5626.4033\n",
            "Epoch 324/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 43.6870\n",
            "Epoch 00324: val_loss did not improve from 5539.19971\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 43.6483 - val_loss: 5603.9487\n",
            "Epoch 325/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 49.3474\n",
            "Epoch 00325: val_loss did not improve from 5539.19971\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 49.3204 - val_loss: 5813.5190\n",
            "Epoch 326/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 49.1185\n",
            "Epoch 00326: val_loss did not improve from 5539.19971\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 49.1566 - val_loss: 5736.6401\n",
            "Epoch 327/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 40.5248\n",
            "Epoch 00327: val_loss did not improve from 5539.19971\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 40.5285 - val_loss: 5615.8203\n",
            "Epoch 328/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 40.2442\n",
            "Epoch 00328: val_loss improved from 5539.19971 to 5516.34717, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 59s 56ms/step - loss: 40.2260 - val_loss: 5516.3472\n",
            "Epoch 329/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 48.6198\n",
            "Epoch 00329: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 48.5882 - val_loss: 5754.6392\n",
            "Epoch 330/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 48.0950\n",
            "Epoch 00330: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 48.0618 - val_loss: 5734.4785\n",
            "Epoch 331/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 46.2805\n",
            "Epoch 00331: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 46.2526 - val_loss: 5624.9697\n",
            "Epoch 332/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 49.8040\n",
            "Epoch 00332: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 49.7961 - val_loss: 5917.0659\n",
            "Epoch 333/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 39.9584\n",
            "Epoch 00333: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 23ms/step - loss: 39.9396 - val_loss: 5589.0029\n",
            "Epoch 334/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 41.8179\n",
            "Epoch 00334: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 41.8176 - val_loss: 5831.8896\n",
            "Epoch 335/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 45.2334\n",
            "Epoch 00335: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 45.2498 - val_loss: 5708.6987\n",
            "Epoch 336/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 43.5162\n",
            "Epoch 00336: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 43.5162 - val_loss: 5808.9194\n",
            "Epoch 337/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 45.4251\n",
            "Epoch 00337: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 45.4574 - val_loss: 5621.5371\n",
            "Epoch 338/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 41.1862\n",
            "Epoch 00338: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 41.1941 - val_loss: 5808.0024\n",
            "Epoch 339/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 38.0053\n",
            "Epoch 00339: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 38.0045 - val_loss: 5847.2861\n",
            "Epoch 340/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 39.3000\n",
            "Epoch 00340: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 39.2759 - val_loss: 5725.5234\n",
            "Epoch 341/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 43.1634\n",
            "Epoch 00341: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 43.1878 - val_loss: 6002.1343\n",
            "Epoch 342/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 39.7962\n",
            "Epoch 00342: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 39.7689 - val_loss: 5838.4863\n",
            "Epoch 343/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 45.0851\n",
            "Epoch 00343: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 45.0604 - val_loss: 5685.3818\n",
            "Epoch 344/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 45.4399\n",
            "Epoch 00344: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 45.4363 - val_loss: 5551.5835\n",
            "Epoch 345/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 42.6745\n",
            "Epoch 00345: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 42.6841 - val_loss: 5762.9941\n",
            "Epoch 346/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 39.1089\n",
            "Epoch 00346: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 39.1278 - val_loss: 5661.2124\n",
            "Epoch 347/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 39.9913\n",
            "Epoch 00347: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 39.9871 - val_loss: 5739.3052\n",
            "Epoch 348/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 40.2081\n",
            "Epoch 00348: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 40.1910 - val_loss: 5867.7456\n",
            "Epoch 349/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 40.3223\n",
            "Epoch 00349: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 40.3157 - val_loss: 5692.3887\n",
            "Epoch 350/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 44.0660\n",
            "Epoch 00350: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 44.0417 - val_loss: 6004.8267\n",
            "Epoch 351/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 38.2076\n",
            "Epoch 00351: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 38.1958 - val_loss: 5723.7456\n",
            "Epoch 352/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 38.5132\n",
            "Epoch 00352: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 38.4819 - val_loss: 5732.0571\n",
            "Epoch 353/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 40.4493\n",
            "Epoch 00353: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 40.4420 - val_loss: 5580.7529\n",
            "Epoch 354/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 37.7249\n",
            "Epoch 00354: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 37.6965 - val_loss: 5659.8530\n",
            "Epoch 355/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 39.2855\n",
            "Epoch 00355: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 39.2616 - val_loss: 5758.6338\n",
            "Epoch 356/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 44.2039\n",
            "Epoch 00356: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 44.1597 - val_loss: 5773.3271\n",
            "Epoch 357/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 41.4731\n",
            "Epoch 00357: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 41.4421 - val_loss: 5660.5405\n",
            "Epoch 358/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 35.6887\n",
            "Epoch 00358: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 35.6668 - val_loss: 5731.0146\n",
            "Epoch 359/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 44.0004\n",
            "Epoch 00359: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 43.9760 - val_loss: 5774.6118\n",
            "Epoch 360/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 42.9045\n",
            "Epoch 00360: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 42.8710 - val_loss: 5870.4497\n",
            "Epoch 361/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 38.5720\n",
            "Epoch 00361: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 38.5596 - val_loss: 5824.9297\n",
            "Epoch 362/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 38.7247\n",
            "Epoch 00362: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 38.7247 - val_loss: 5755.2646\n",
            "Epoch 363/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 33.3251\n",
            "Epoch 00363: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 33.3015 - val_loss: 5731.5894\n",
            "Epoch 364/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 57.0617\n",
            "Epoch 00364: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 57.0390 - val_loss: 5536.8188\n",
            "Epoch 365/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 33.0109\n",
            "Epoch 00365: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 33.0031 - val_loss: 5599.8765\n",
            "Epoch 366/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 151.7152\n",
            "Epoch 00366: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 151.8207 - val_loss: 5682.7983\n",
            "Epoch 367/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 43.5288\n",
            "Epoch 00367: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 43.5288 - val_loss: 5694.3403\n",
            "Epoch 368/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 29.8729\n",
            "Epoch 00368: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 29.8841 - val_loss: 5676.6172\n",
            "Epoch 369/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 23.4328\n",
            "Epoch 00369: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 23.4242 - val_loss: 5705.7593\n",
            "Epoch 370/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 25.1175\n",
            "Epoch 00370: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 25.1203 - val_loss: 5698.5630\n",
            "Epoch 371/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 35.0704\n",
            "Epoch 00371: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 35.0514 - val_loss: 5812.1055\n",
            "Epoch 372/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 43.3653\n",
            "Epoch 00372: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 23ms/step - loss: 43.3653 - val_loss: 5706.1904\n",
            "Epoch 373/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 36.8540\n",
            "Epoch 00373: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 36.9840 - val_loss: 5719.5156\n",
            "Epoch 374/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 64.6315\n",
            "Epoch 00374: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 64.6241 - val_loss: 5867.0430\n",
            "Epoch 375/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 36.2502\n",
            "Epoch 00375: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 36.2690 - val_loss: 5701.2759\n",
            "Epoch 376/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 37.2206\n",
            "Epoch 00376: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 37.2110 - val_loss: 5664.4214\n",
            "Epoch 377/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 33.7779\n",
            "Epoch 00377: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 33.7779 - val_loss: 5683.6543\n",
            "Epoch 378/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 38.7621\n",
            "Epoch 00378: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 38.7271 - val_loss: 5586.7710\n",
            "Epoch 379/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 45.7439\n",
            "Epoch 00379: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 45.7104 - val_loss: 5808.5688\n",
            "Epoch 380/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 38.6890\n",
            "Epoch 00380: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 38.6883 - val_loss: 5646.1162\n",
            "Epoch 381/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 32.0321\n",
            "Epoch 00381: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 32.0457 - val_loss: 5656.5498\n",
            "Epoch 382/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 36.0626\n",
            "Epoch 00382: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 36.0626 - val_loss: 5794.2651\n",
            "Epoch 383/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 47.5740\n",
            "Epoch 00383: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 47.5516 - val_loss: 5905.4561\n",
            "Epoch 384/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 40.0760\n",
            "Epoch 00384: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 40.0480 - val_loss: 5882.5249\n",
            "Epoch 385/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 54.6688\n",
            "Epoch 00385: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 23ms/step - loss: 54.6321 - val_loss: 5630.3862\n",
            "Epoch 386/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 37.7615\n",
            "Epoch 00386: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 37.8058 - val_loss: 5702.4980\n",
            "Epoch 387/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 28.9887\n",
            "Epoch 00387: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 28.9791 - val_loss: 5809.7300\n",
            "Epoch 388/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 28.8310\n",
            "Epoch 00388: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 28.8136 - val_loss: 5546.1035\n",
            "Epoch 389/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 49.8316\n",
            "Epoch 00389: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 49.8559 - val_loss: 5783.9268\n",
            "Epoch 390/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 43.7241\n",
            "Epoch 00390: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 43.6997 - val_loss: 5766.1260\n",
            "Epoch 391/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 31.7744\n",
            "Epoch 00391: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 31.7748 - val_loss: 5867.5005\n",
            "Epoch 392/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 33.2068\n",
            "Epoch 00392: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 33.2068 - val_loss: 5735.0679\n",
            "Epoch 393/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 38.7203\n",
            "Epoch 00393: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 38.7403 - val_loss: 5776.2129\n",
            "Epoch 394/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 53.0588\n",
            "Epoch 00394: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 53.0766 - val_loss: 5695.5718\n",
            "Epoch 395/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 40.2404\n",
            "Epoch 00395: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 40.2133 - val_loss: 5931.4893\n",
            "Epoch 396/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 46.1699\n",
            "Epoch 00396: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 46.1451 - val_loss: 6052.3643\n",
            "Epoch 397/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 39.6080\n",
            "Epoch 00397: val_loss did not improve from 5516.34717\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 39.6080 - val_loss: 5736.3955\n",
            "Epoch 398/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 31.7100\n",
            "Epoch 00398: val_loss improved from 5516.34717 to 5513.32715, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 55s 51ms/step - loss: 31.6958 - val_loss: 5513.3271\n",
            "Epoch 399/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 32.8043\n",
            "Epoch 00399: val_loss did not improve from 5513.32715\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 32.8421 - val_loss: 5700.9595\n",
            "Epoch 400/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 35.6061\n",
            "Epoch 00400: val_loss did not improve from 5513.32715\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 35.6112 - val_loss: 5829.2432\n",
            "Epoch 401/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 37.5232\n",
            "Epoch 00401: val_loss did not improve from 5513.32715\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 37.5232 - val_loss: 5681.1821\n",
            "Epoch 402/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 36.4270\n",
            "Epoch 00402: val_loss did not improve from 5513.32715\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 36.4130 - val_loss: 5764.6567\n",
            "Epoch 403/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 38.6134\n",
            "Epoch 00403: val_loss did not improve from 5513.32715\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 38.5798 - val_loss: 6010.6973\n",
            "Epoch 404/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 40.6397\n",
            "Epoch 00404: val_loss did not improve from 5513.32715\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 40.6641 - val_loss: 5778.4038\n",
            "Epoch 405/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 37.6808\n",
            "Epoch 00405: val_loss did not improve from 5513.32715\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 37.7264 - val_loss: 5762.0054\n",
            "Epoch 406/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 29.6574\n",
            "Epoch 00406: val_loss did not improve from 5513.32715\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 29.6574 - val_loss: 5871.0425\n",
            "Epoch 407/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 32.7160\n",
            "Epoch 00407: val_loss did not improve from 5513.32715\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 32.7354 - val_loss: 5741.8721\n",
            "Epoch 408/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 34.7781\n",
            "Epoch 00408: val_loss did not improve from 5513.32715\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 34.8076 - val_loss: 5643.4619\n",
            "Epoch 409/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 35.0564\n",
            "Epoch 00409: val_loss did not improve from 5513.32715\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 35.0677 - val_loss: 5973.5518\n",
            "Epoch 410/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 34.0476\n",
            "Epoch 00410: val_loss did not improve from 5513.32715\n",
            "1065/1065 [==============================] - 24s 23ms/step - loss: 34.0309 - val_loss: 5811.8926\n",
            "Epoch 411/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 33.5575\n",
            "Epoch 00411: val_loss did not improve from 5513.32715\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 33.5575 - val_loss: 5984.4961\n",
            "Epoch 412/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 37.8164\n",
            "Epoch 00412: val_loss did not improve from 5513.32715\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 37.7963 - val_loss: 5705.1602\n",
            "Epoch 413/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 32.2116\n",
            "Epoch 00413: val_loss did not improve from 5513.32715\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 32.2456 - val_loss: 5812.2046\n",
            "Epoch 414/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 35.0466\n",
            "Epoch 00414: val_loss did not improve from 5513.32715\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 35.0349 - val_loss: 5807.6743\n",
            "Epoch 415/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 37.9242\n",
            "Epoch 00415: val_loss did not improve from 5513.32715\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 38.0190 - val_loss: 5863.7368\n",
            "Epoch 416/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 44.8200\n",
            "Epoch 00416: val_loss did not improve from 5513.32715\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 44.8200 - val_loss: 5870.0376\n",
            "Epoch 417/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 45.4971\n",
            "Epoch 00417: val_loss did not improve from 5513.32715\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 45.4895 - val_loss: 5774.8262\n",
            "Epoch 418/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 48.6250\n",
            "Epoch 00418: val_loss did not improve from 5513.32715\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 48.5849 - val_loss: 5599.3975\n",
            "Epoch 419/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 37.0400\n",
            "Epoch 00419: val_loss did not improve from 5513.32715\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 37.0494 - val_loss: 5819.8501\n",
            "Epoch 420/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 24.6219\n",
            "Epoch 00420: val_loss did not improve from 5513.32715\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 24.6057 - val_loss: 5874.4668\n",
            "Epoch 421/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 28.9979\n",
            "Epoch 00421: val_loss improved from 5513.32715 to 5486.54346, saving model to best_PCA3.h5\n",
            "1065/1065 [==============================] - 59s 55ms/step - loss: 28.9979 - val_loss: 5486.5435\n",
            "Epoch 422/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 34.3158\n",
            "Epoch 00422: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 34.2855 - val_loss: 5830.1411\n",
            "Epoch 423/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 32.6723\n",
            "Epoch 00423: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 32.6765 - val_loss: 5893.0215\n",
            "Epoch 424/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 44.9972\n",
            "Epoch 00424: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 44.9972 - val_loss: 6014.1660\n",
            "Epoch 425/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 37.1338\n",
            "Epoch 00425: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 37.1821 - val_loss: 5923.5454\n",
            "Epoch 426/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 28.5800\n",
            "Epoch 00426: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 28.5788 - val_loss: 6013.3667\n",
            "Epoch 427/1000\n",
            "1065/1065 [==============================] - ETA: 0s - loss: 28.7222\n",
            "Epoch 00427: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 28.7222 - val_loss: 5912.8311\n",
            "Epoch 428/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 35.6155\n",
            "Epoch 00428: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 35.6148 - val_loss: 5842.4517\n",
            "Epoch 429/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 37.5034\n",
            "Epoch 00429: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 37.5520 - val_loss: 6031.6514\n",
            "Epoch 430/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 33.5153\n",
            "Epoch 00430: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 33.4926 - val_loss: 5877.6655\n",
            "Epoch 431/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 28.4359\n",
            "Epoch 00431: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 28.4762 - val_loss: 5834.8564\n",
            "Epoch 432/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 30.3253\n",
            "Epoch 00432: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 30.3631 - val_loss: 5979.2090\n",
            "Epoch 433/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 29.6475\n",
            "Epoch 00433: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 29.6522 - val_loss: 6198.8184\n",
            "Epoch 434/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 33.5712\n",
            "Epoch 00434: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 33.5621 - val_loss: 5944.9717\n",
            "Epoch 435/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 35.2172\n",
            "Epoch 00435: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 35.2003 - val_loss: 5975.0190\n",
            "Epoch 436/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 29.0155\n",
            "Epoch 00436: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 29.0238 - val_loss: 5923.3989\n",
            "Epoch 437/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 28.6633\n",
            "Epoch 00437: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 28.6554 - val_loss: 6051.1011\n",
            "Epoch 438/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 34.2541\n",
            "Epoch 00438: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 34.2429 - val_loss: 6095.0884\n",
            "Epoch 439/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 36.2612\n",
            "Epoch 00439: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 36.2338 - val_loss: 6125.6450\n",
            "Epoch 440/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 30.9139\n",
            "Epoch 00440: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 30.9062 - val_loss: 6014.0449\n",
            "Epoch 441/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 27.5396\n",
            "Epoch 00441: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 27.5181 - val_loss: 6011.3799\n",
            "Epoch 442/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 29.0106\n",
            "Epoch 00442: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 29.0009 - val_loss: 5956.7007\n",
            "Epoch 443/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 38.4658\n",
            "Epoch 00443: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 38.4542 - val_loss: 5793.1587\n",
            "Epoch 444/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 39.2987\n",
            "Epoch 00444: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 39.2808 - val_loss: 5981.7798\n",
            "Epoch 445/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 35.0361\n",
            "Epoch 00445: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 35.0289 - val_loss: 5763.8501\n",
            "Epoch 446/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 29.6809\n",
            "Epoch 00446: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 29.7146 - val_loss: 5954.2017\n",
            "Epoch 447/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 26.2868\n",
            "Epoch 00447: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 26.3029 - val_loss: 6015.4087\n",
            "Epoch 448/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 28.2075\n",
            "Epoch 00448: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 28.2133 - val_loss: 6103.3843\n",
            "Epoch 449/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 34.5698\n",
            "Epoch 00449: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 34.5471 - val_loss: 6116.2100\n",
            "Epoch 450/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 33.5512\n",
            "Epoch 00450: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 33.5450 - val_loss: 6217.7739\n",
            "Epoch 451/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 35.7176\n",
            "Epoch 00451: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 35.7039 - val_loss: 6019.6943\n",
            "Epoch 452/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 32.0392\n",
            "Epoch 00452: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 32.0286 - val_loss: 5785.5376\n",
            "Epoch 453/1000\n",
            "1063/1065 [============================>.] - ETA: 0s - loss: 29.1083\n",
            "Epoch 00453: val_loss did not improve from 5486.54346\n",
            "1065/1065 [==============================] - 24s 22ms/step - loss: 29.3592 - val_loss: 5905.4077\n",
            "Epoch 454/1000\n",
            " 946/1065 [=========================>....] - ETA: 2s - loss: 29.0142"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}