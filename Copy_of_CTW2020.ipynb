{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CTW2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kkuntal990/CTW_2020/blob/master/Copy_of_CTW2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5_VrAvQzC4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorflow_version 1.x\n",
        "import numpy as np # linear algebra\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import h5py\n",
        "import pandas as pd\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMJ51RI26oyA",
        "colab_type": "code",
        "outputId": "878efc76-2588-43a8-b4b6-114da538f0ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Dense, LeakyReLU, Input, Conv2D, AveragePooling2D, MaxPooling2D, Dropout, Flatten\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qjIqybShB3v",
        "colab_type": "code",
        "outputId": "b3065fe1-7f07-4ca0-cdd7-f029e2b6f505",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgUYk18m2n6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/CTW_2019/CTW2019_Dataset_h5.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/drive/My Drive/CTW_2019/\")\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glYECAAzzNNF",
        "colab_type": "code",
        "outputId": "b8bd2327-4cad-45a2-be05-99d1f0d98888",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def find(SNR):\n",
        "    #H_R.shape = (512,56,924,5)\n",
        "    \n",
        "    #print(temp.shape)\n",
        "    idx  = np.argmax(SNR, axis=1)\n",
        "    return idx\n",
        "    \n",
        "def preprocess(H_Re, idx):\n",
        "    #temp = np.zeros(H_Re.shape[:-1])\n",
        "    for i in range(H_Re.shape[0]):\n",
        "        for j in range(H_Re.shape[1]):\n",
        "            \n",
        "            H_Re[i,j,:,0] = H_Re[i,j,:,idx[i,j]]\n",
        "    return H_Re[:,:,:,0]\n",
        "\n",
        "def preprocess2(H_Re, idx):\n",
        "    temp = np.zeros(H_Re.shape[:-1])\n",
        "    for i in range(H_Re.shape[0]):\n",
        "        for j in range(H_Re.shape[1]):\n",
        "            temp[i,j] = H_Re[i,j,idx[i,j]]\n",
        "    return temp\n",
        "\n",
        "def get_data(data_file):\n",
        "    f = h5py.File(data_file, 'r')\n",
        "    H_Re = f['H_Re'][:] #shape (sample size, 56, 924, 5)\n",
        "    H_Im = f['H_Im'][:] #shape (sample size, 56, 924, 5)\n",
        "    SNR = f['SNR'][:] #shape (sample size, 56, 5)\n",
        "    Pos = f['Pos'][:] #shape(sample size, 3)\n",
        "    f.close()\n",
        "    return H_Re, H_Im, SNR, Pos\n",
        "\n",
        "def get_data2(data_file):\n",
        "    f = h5py.File(data_file, 'r')\n",
        "    H_Re = f['H_Re'][:] #shape (sample size, 56, 924, 5)\n",
        "    H_Im = f['H_Im'][:] #shape (sample size, 56, 924, 5)\n",
        "    SNR = f['SNR'][:] #shape (sample size, 56, 5)\n",
        "    #Pos = f['Pos'][:] #shape(sample size, 3)\n",
        "    f.close()\n",
        "    return H_Re, H_Im, SNR\n",
        "'''\n",
        "def mag(data):x\n",
        "\n",
        "    dim = H.shape[1]\n",
        "    H_re = H[:, :dim/2]\n",
        "    H_Im = H[:, dim/2:]\n",
        "    return np.sqrt(H_re**2 + H_Im**2)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef mag(data):x\\n\\n    dim = H.shape[1]\\n    H_re = H[:, :dim/2]\\n    H_Im = H[:, dim/2:]\\n    return np.sqrt(H_re**2 + H_Im**2)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALv8-1mzkVlJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "\n",
        "def load_labelled(path):\n",
        "    f = h5py.File(path, 'r')\n",
        "    H_Re = f['H_Re'][:] #shape (sample size, 56, 924, 5)\n",
        "    H_Im = f['H_Im'][:] #shape (sample size, 56, 924, 5)\n",
        "    SNR = f['SNR'][:] #shape (sample size, 56, 5)\n",
        "    Pos = f['Pos'][:] #shape(sample size, 3)\n",
        "    f.close()\n",
        "    print(1)\n",
        "    return H_Re, H_Im, SNR, Pos\n",
        "\n",
        "def load_unlabelled(path):\n",
        "    f = h5py.File(path, 'r')\n",
        "    '''\n",
        "    H_Re = f['H_Re'][:] #shape (sample size, 56, 924, 5)\n",
        "    H_Im = f['H_Im'][:] #shape (sample size, 56, 924, 5)\n",
        "    SNR  = f['SNR'][:]  #shape (sample size, 56, 5)\n",
        "    print(SNR.shape)\n",
        "    '''\n",
        "  \n",
        "    print(f.keys())\n",
        "    #H = f['dataset_1'][:]\n",
        "    H = f['r_Position'][:]\n",
        "    f.close()\n",
        "    return H\n",
        "\n",
        "def load_unlabelled2(path):\n",
        "    f = h5py.File(path, 'r')\n",
        "    '''\n",
        "    H_Re = f['H_Re'][:] #shape (sample size, 56, 924, 5)\n",
        "    H_Im = f['H_Im'][:] #shape (sample size, 56, 924, 5)\n",
        "    SNR  = f['SNR'][:]  #shape (sample size, 56, 5)\n",
        "    print(SNR.shape)\n",
        "    '''\n",
        "  \n",
        "    print(f.keys())\n",
        "    H = f['dataset_1'][:]\n",
        "    #H = f['r_Position'][:]\n",
        "    f.close()\n",
        "    return H"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIJETmepqiyw",
        "colab_type": "code",
        "outputId": "9258db93-ca34-41ac-de9b-3d8245a55534",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#H_Re , H_Im , SNR , Pos = load_labelled(\"/content/drive/My Drive/CTW2020/CTW2020_labelled_data/file_1.hdf5\")\n",
        "#print(os.listdir(\"/content/drive/My Drive/CTW2020/Processed Data/\"))\n",
        "#os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
        "#tH_Re , tH_Im , tSNR  = load_unlabelled(\"/content/drive/My Drive/CTW_2019/undata.hdf5\")\n",
        "H = load_unlabelled2('/content/drive/My Drive/CTW_2019/data2019.h5')\n",
        "#H_Re, H_Im, SNR  = np.concatenate((H_Re, tH_Re)), np.concatenate((H_Im, tH_Im)), np.concatenate((SNR, tSNR))\n",
        "#del tSNR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<KeysViewHDF5 ['dataset_1']>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDZOXokZoXBk",
        "colab_type": "code",
        "outputId": "09897c02-f400-42d8-d3a7-8e2487abc270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "print(H.shape)\n",
        "H1 = np.swapaxes(H,0,2)\n",
        "x = np.linspace(0,65,66)\n",
        "y = H[:,7,8678]\n",
        "y1 = H1[8678, 7, :]\n",
        "plt.plot(x,y)\n",
        "plt.plot(x,y1)\n",
        "print(H1.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(66, 16, 17486)\n",
            "(17486, 16, 66)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKTOG84MwJ9N",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEDPsuqUv1jK",
        "colab_type": "code",
        "outputId": "3cf4d60f-9bbc-4b5a-be42-24c09ea124c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Y_pos = load_unlabelled('/content/drive/My Drive/CTW_2019/r_Position_CTW_Train.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<KeysViewHDF5 ['r_Position']>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYbnLAY9wM98",
        "colab_type": "code",
        "outputId": "348b47a7-3402-4966-abe5-ffc93d83ee95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(Y_pos.shape)\n",
        "Y = np.swapaxes(Y_pos, 0,1)\n",
        "print(Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 17486)\n",
            "(17486, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_-LJGH_3p6M",
        "colab_type": "code",
        "outputId": "57f08141-eb47-4b4c-eddb-dfc716d9afe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(H.shape)\n",
        "H_Re = H[0,:,:,:]\n",
        "H_Im = H[1,:,:,:]\n",
        "\n",
        "data2 = np.sqrt(H_Re**2 + H_Im**2)\n",
        "data2 = data2.reshape(17486,16,924)\n",
        "print(data2.shape)\n",
        "del H_Re, H_Im"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 924, 16, 17486)\n",
            "(17486, 16, 924)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yYAY57Zsxbf",
        "colab_type": "code",
        "outputId": "e59ec8cc-3f0f-4e5b-80aa-cf675a90cc1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tH_Re.shape)\n",
        "del tSNR\n",
        "#del tH_Re, tH_Im, tSNR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(36192, 56, 924)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRDs3eImzYvY",
        "colab_type": "code",
        "outputId": "8ea6020e-b43d-4bff-c8ce-cfe7e31b2af0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "#CTW_labelled = \"/content/drive/My Drive/CTW2020/CTW2020_Unlabelled/\"\n",
        "#import os\n",
        "#print(os.listdir(\"/content/drive/My Drive/CTW2020/Processed Data\"))\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "#%%\n",
        "x = np.linspace(1,924,924,dtype=fworksloat)\n",
        "\n",
        "y = []\n",
        "\n",
        "for i in range(924):\n",
        "  y.append(data[9,1,i])\n",
        "\n",
        "#data_file = CTW_labelled+\"file_\"+str(1)+\".hdf5\"\n",
        "#H_Re, H_Im, SNR = get_data2(data_file)\n",
        "\n",
        "#print(H_Re[1,1,1,:])\n",
        "\n",
        "#idx = find(tSNR)\n",
        "#del tSNR\n",
        "#tH_Re = preprocess(tH_Re, idx)r\n",
        "#tH_Im = preprocess(tH_Im, idx)\n",
        "#SNR = preprocess2(SNR, idx)\n",
        "#print(SNR.shape)\n",
        "#del idx"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-537760b65fdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#%%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m924\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m924\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfworksloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'fworksloat' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-Kt7gGD32f7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "\n",
        "for i in range(2,15):\n",
        "    temp = CTW_labelled + \"file_\"+str(i)+\".hdf5\"\n",
        "    tH_Re, tH_Im, tSNR = get_data2(temp)\n",
        "    idx = find(tSNR)\n",
        "    tH_Re = preprocess(tH_Re, idx)\n",
        "    tH_Im = preprocess(tH_Im, idx)\n",
        "    tSNR = preprocess2(tSNR, idx)\n",
        "    H_Re, H_Im, SNR  = np.concatenate((H_Re, tH_Re)), np.concatenate((H_Im, tH_Im)), np.concatenate((SNR, tSNR))\n",
        "\n",
        "del tH_Re,tH_Im,tSNR'''x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klAI02iW5MIg",
        "colab_type": "code",
        "outputId": "32b766c1-1739-4bc5-e7ae-8aade75f4a6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#from sklearn.preprocessing import MinMaxScaler\n",
        "samples = tH_Re.shape[0]\n",
        "#H_Re = tH_Re.reshape((samples,-1))\n",
        "#print(tH_Re.shape)\n",
        "#H_Im = tH_Im.reshape((samples,-1))\n",
        "#SNR = SNR.reshape((samples,-1))\n",
        "#Pos = Pos.reshape((samples,-1))\n",
        "\n",
        "#data = np.sqrt(H_Re**2 + H_Im**2)\n",
        "data2 = np.sqrt(tH_Re**2 + tH_Im**2)\n",
        "del tH_Re , tH_Im\n",
        "print(data2.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(36192, 56, 924)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4xOwa9k5PHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "#%%\n",
        "dim1 = int(data2.shape[0]/2)\n",
        "#dim1 = 10\n",
        "dim2 = data2.shape[1]\n",
        "new_dim = 66\n",
        "data3 = np.zeros((dim1,dim2, new_dim))\n",
        "\n",
        "#Polynomial fitting code\n",
        "t1 = time.time()\n",
        "R2s = []\n",
        "w = np.linspace(0,1,22)\n",
        "for u in range(dim1):\n",
        "    for v in range(dim2):\n",
        "        \n",
        "        degrees = [4,5,6,7,8]\n",
        "        \n",
        "        batches = [0,242,220,473,451,704,682,924]  #len = 8\n",
        "        final_x = np.linspace(1,924,924)\n",
        "        final_y = np.zeros((924,))\n",
        "        prev = np.zeros([22,])\n",
        "        for i in range(4):\n",
        "            x = np.linspace(batches[i*2],batches[2*i + 1],-batches[i*2]+batches[2*i + 1])\n",
        "           # print()\n",
        "            #print(x.shape)\n",
        "            y = []\n",
        "        \n",
        "            for j in range(batches[i*2],batches[2*i+1]):\n",
        "                y.append(data2[u + dim1,v,j])\n",
        "             \n",
        "            y = np.array(y)\n",
        "            x = x[:, np.newaxis]\n",
        "            y = y[:, np.newaxis]\n",
        "            r2 = np.Infinity\n",
        "            best_deg = 0\n",
        "            for deg in degrees:\n",
        "                polynomial_features= PolynomialFeatures(degree=deg, interaction_only=False)\n",
        "                x_poly = polynomial_features.fit_transform(x)\n",
        "                model = LinearRegression()\n",
        "                model.fit(x_poly, y)\n",
        "                y_poly_pred = model.predict(x_poly)\n",
        "                \n",
        "                rmse = np.sqrt(mean_squared_error(y,y_poly_pred))\n",
        "                #temp = r2_score(y,y_poly_pred)\n",
        "                if rmse < r2:\n",
        "                    best_deg = deg\n",
        "                    r2 = rmse\n",
        "                    final_y[batches[i*2]:batches[2*i+1]] = y_poly_pred.reshape((-1))\n",
        "                    #print(str(r2) + \" Testing \")\n",
        "                    \n",
        "            #print(\"Best found \" + str(r2))\n",
        "            R2s.append(rmse)\n",
        "            \n",
        "            tmp1 = final_y[batches[i*2]:batches[i*2]+22]\n",
        "            if prev.all() != 0:\n",
        "                final_y[batches[i*2]:batches[i*2]+22] = tmp1*w + prev*(1-w)\n",
        "            prev = final_y[batches[i*2 + 1]-22:batches[i*2 + 1]]\n",
        "            \n",
        "        data3[u,v,:] = [final_y[i] for i in range(0,len(final_y), 14)]    \n",
        "    t2 = time.time() \n",
        "    print(str(u) + \"th of \" + str(dim1))\n",
        "    print(\"Time elasped: \" + str((t2-t1)/60) + \" mins.\")    \n",
        "    t2 = time.time() \n",
        "   # print(str(u) + \"th of \" + str(dim1))\n",
        "   # print(\"Time elasped: \" + str((t2-t1)/60) + \" mins.\")\n",
        "#%%\n",
        "t3 = time.time()\n",
        "print(\"DONE\")\n",
        "print(\"Total time: \" + str((t3-t1)/3600) + \" hrs.\")\n",
        "#plt.plot(final_x, final_y)\n",
        "\n",
        "#x1 = np.linspace(1,924,924,dtype=float)\n",
        "\n",
        "#y1 = []\n",
        "'''\n",
        "for i in range(924):\n",
        "  y1.append(data[9,1,i])\n",
        "\n",
        "y1 = np.array(y1)\n",
        "\n",
        "plt.scatter(x1,y1,s=12)\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6LeQPPoRFa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing if above works or not\n",
        "\n",
        "x1 = np.linspace(1,924,924,dtype=float)\n",
        "x2 = np.linspace(1,924,66,dtype=float)\n",
        "# y1 =\n",
        "\n",
        "# for i in range(924):\n",
        "#   y1.append(data[9,1,i])\n",
        "\n",
        "# y1 = np.array(y1)\n",
        "\n",
        "# plt.scatter(x1,y1,s=12)\n",
        "y1 = data3[41,1,:]\n",
        "#asd\n",
        "plt.plot(x2,y1,'r')\n",
        "plt.scatter(x1, data2[41,1,:],s=12)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZofQxkpWl4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hf = h5py.File('/content/drive/My Drive/CTW_2019/data_feat2.h5', 'w')\n",
        "hf.create_dataset('dataset_1', data=data3)\n",
        "hf.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8YKT5PUR7HJ",
        "colab_type": "code",
        "outputId": "da3706c3-3d5b-422a-8a22-8ea30cfffd7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "pca_50 = PCA(n_components=100)\n",
        "y = pca_50.fit_transform(data)\n",
        "s\n",
        "print('Cumulative explained variation for 50 principal components: {}'.format(np.sum(pca_50.explained_variance_ratio_)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cumulative explained variation for 50 principal components: 0.9999203382894867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWMhCYm_5QPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.optimizers import Adadelta, Adam, RMSprop\n",
        "\n",
        "def create_model(input_dim):\n",
        "    inp = Input(shape=(input_dim))\n",
        "    x = Dense(1024, activation='relu')(inp)\n",
        "    #layer3 = Dense(512, activation='relu')(layer2)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    encoded = Dense(512, activation='relu')(x)\n",
        "    x =  Dense(1025, activation='relu')(encoded)\n",
        "    #layer6 = Dense(512, activation='relu')(layer5)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    \n",
        "    decoded = Dense(input_dim, activation='relu')(x)\n",
        "    \n",
        "    \n",
        "    return Model(inp, encoded), Model(inp, decoded)\n",
        "\n",
        "\n",
        "def data_gen(data):\n",
        "    for i in range(len(data)):\n",
        "        yield (data[i:i+1],data[i:i+1])\n",
        "\n",
        "def data_gen2(data, target):\n",
        "    for i in range(len(data)):\n",
        "        yield (data[i:i+1],target[i:i+1])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sIZkLCcsjxG",
        "colab_type": "code",
        "outputId": "ea1fcd66-4eb6-4e7d-dbc5-f267a5796bd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(H.shape)\n",
        "print(Y_pos.shape)\n",
        "\n",
        "\n",
        "\n",
        "print(data19.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(66, 16, 17486)\n",
            "(3, 17486)\n",
            "(17486, 16, 66, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaOEgimtp6wP",
        "colab_type": "code",
        "outputId": "17660c95-f0ec-42be-da10-21e0b52321b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "data19 = np.concatenate((H1, Y_pos[:,:,None]), axis=0)\n",
        "\n",
        "print(data19.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-b214d8692cfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata19\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata19\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 16 and the array at index 1 has size 3"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVhscfScpt22",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KKGuHAEhfx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mlp():\n",
        "  inp = Input(shape=(16,66))\n",
        "  x = Flatten()(inp)\n",
        "  x = Dense(1024,activation = 'relu')(x)\n",
        "  #x = Dense(1024, activation = 'relu')(x)\n",
        "  x = Dropout(0.03)(x)\n",
        "  x = Dense(512, activation = 'relu',kernel_initializer='glorot_uniform',\n",
        "                bias_initializer='zeros')(x)\n",
        "  x = Dropout(0.03)(x)\n",
        "  x = Dense(256, activation = 'relu',kernel_initializer='glorot_uniform',\n",
        "                bias_initializer='zeros')(x)\n",
        "  x = Dropout(0.03)(x)\n",
        "  x = Dense(128, activation = 'relu',kernel_initializer='glorot_uniform',\n",
        "                bias_initializer='zeros')(x)\n",
        "  x = Dropout(0.03)(x)\n",
        "  x = Dense(32, activation = 'relu',kernel_initializer='glorot_uniform',\n",
        "                bias_initializer='ones')(x)\n",
        "  x = Dropout(0.03)(x)\n",
        "  x = Dense(12, activation = 'relu',kernel_initializer='glorot_uniform',\n",
        "                bias_initializer='ones')(x)\n",
        "  x = Dropout(0.03)(x)\n",
        "  op = Dense(3, activation = 'relu',kernel_initializer='glorot_uniform',\n",
        "                bias_initializer='ones')(x)\n",
        "  return Model(inp, op)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqC0tWCXwk64",
        "colab_type": "code",
        "outputId": "a678b0ef-b518-4d84-9174-ada64e5970c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "traindata,valdata  = train_test_split(H1, test_size=0.1, random_state=54) \n",
        "trainy,valy  = train_test_split(Y, test_size=0.1, random_state=54) \n",
        "print(traindata.shape)\n",
        "steps = len(traindata)\n",
        "print(steps)\n",
        "val_Steps = len(valdata)\n",
        "print(val_Steps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15737, 16, 66)\n",
            "15737\n",
            "1749\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3AbN9AhkV3T",
        "colab_type": "code",
        "outputId": "8b569507-058a-4d0d-e37e-97b96430c796",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test = train_test_split(H1, test_size=0.1, random_state=42, shuffle=True)\n",
        "y_train,y_test = train_test_split(Y, test_size=0.1, random_state=42, shuffle=True)\n",
        "#print(H_new.shape,pos.shape)\n",
        "\n",
        "print(X_train.shape,X_test.shape)\n",
        "print(y_train.shape,y_test.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15737, 16, 66) (1749, 16, 66)\n",
            "(15737, 3) (1749, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrSpM2lpmGjo",
        "colab_type": "code",
        "outputId": "00f87ace-a0ad-48f2-f2d6-8af553e92795",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "mlp_2019 = mlp()\n",
        "from sklearn.model_selection import KFold\n",
        "opt = RMSprop(learning_rate=0.001, decay=1e-6)\n",
        "mlp_2019.compile(optimizer=opt,loss = 'mean_squared_error')\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience = 20)\n",
        "checkpointer = ModelCheckpoint('/content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5', verbose=1, save_best_only=True)\n",
        "mlp_2019.fit(X_train, y_train, epochs = 150, verbose=1, batch_size = 20, validation_split=0.1, callbacks = [checkpointer, early_stopping])\n",
        "\n",
        "error = []\n",
        "\n",
        "kfold = KFold(10, True, 1)\n",
        "# enumerate splits\n",
        "'''\n",
        "for train, test in kfold.split(H1):\n",
        "  trainy, testy = Y[train], Y[test]\n",
        "  traindata, testdata = H1[train], H1[test]\n",
        "  mlp_2019  = mlp()\n",
        "  mlp_2019.compile(optimizer=Adam(lr=0.0005),loss = 'mean_squared_error', metrics = ['accuracy'])\n",
        "  mlp_2019.fit(traindata, trainy, epochs = 200, batch_size = 20, verbose=1, validation_split=0.1, callbacks = [checkpointer])\n",
        "  error.append(mlp_2019.evaluate(testdata, testy))\n",
        "\n",
        "\n",
        "#mlp_2019.fit_generator(kfoldcv(H1,Y)[0],validation_data = kfoldcv(H1,Y)[1], epochs = 150, steps_per_epoch = len(kfoldcv(H1,Y)[0][0]) ,\n",
        "#                        validation_steps = len(kfoldcv(H1,Y)[1][0]), callbacks=[checkpointer])\n",
        "\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 14163 samples, validate on 1574 samples\n",
            "Epoch 1/150\n",
            "14163/14163 [==============================] - 4s 282us/step - loss: 0.5747 - val_loss: 0.6830\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.68302, saving model to /content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\n",
            "Epoch 2/150\n",
            "14163/14163 [==============================] - 4s 258us/step - loss: 0.4406 - val_loss: 0.3704\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.68302 to 0.37037, saving model to /content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\n",
            "Epoch 3/150\n",
            "14163/14163 [==============================] - 4s 260us/step - loss: 0.3919 - val_loss: 0.5839\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.37037\n",
            "Epoch 4/150\n",
            "14163/14163 [==============================] - 4s 265us/step - loss: 0.3625 - val_loss: 0.3409\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.37037 to 0.34093, saving model to /content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\n",
            "Epoch 5/150\n",
            "14163/14163 [==============================] - 4s 260us/step - loss: 0.3401 - val_loss: 0.4612\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.34093\n",
            "Epoch 6/150\n",
            "14163/14163 [==============================] - 4s 262us/step - loss: 0.3224 - val_loss: 0.2827\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.34093 to 0.28270, saving model to /content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\n",
            "Epoch 7/150\n",
            "14163/14163 [==============================] - 4s 253us/step - loss: 0.3074 - val_loss: 0.2698\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.28270 to 0.26984, saving model to /content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\n",
            "Epoch 8/150\n",
            "14163/14163 [==============================] - 4s 253us/step - loss: 0.2952 - val_loss: 0.2855\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.26984\n",
            "Epoch 9/150\n",
            "14163/14163 [==============================] - 4s 263us/step - loss: 0.2805 - val_loss: 0.2864\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.26984\n",
            "Epoch 10/150\n",
            "14163/14163 [==============================] - 4s 254us/step - loss: 0.2742 - val_loss: 0.2920\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.26984\n",
            "Epoch 11/150\n",
            "14163/14163 [==============================] - 4s 252us/step - loss: 0.2658 - val_loss: 0.2823\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.26984\n",
            "Epoch 12/150\n",
            "14163/14163 [==============================] - 4s 258us/step - loss: 0.2572 - val_loss: 0.2495\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.26984 to 0.24947, saving model to /content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\n",
            "Epoch 13/150\n",
            "14163/14163 [==============================] - 4s 255us/step - loss: 0.2515 - val_loss: 0.2493\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.24947 to 0.24926, saving model to /content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\n",
            "Epoch 14/150\n",
            "14163/14163 [==============================] - 4s 255us/step - loss: 0.2426 - val_loss: 0.3275\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.24926\n",
            "Epoch 15/150\n",
            "14163/14163 [==============================] - 4s 260us/step - loss: 0.2400 - val_loss: 0.2314\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.24926 to 0.23142, saving model to /content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\n",
            "Epoch 16/150\n",
            "14163/14163 [==============================] - 4s 255us/step - loss: 0.2338 - val_loss: 0.2372\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.23142\n",
            "Epoch 17/150\n",
            "14163/14163 [==============================] - 4s 256us/step - loss: 0.2247 - val_loss: 0.2279\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.23142 to 0.22788, saving model to /content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\n",
            "Epoch 18/150\n",
            "14163/14163 [==============================] - 4s 257us/step - loss: 0.2204 - val_loss: 0.2543\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.22788\n",
            "Epoch 19/150\n",
            "14163/14163 [==============================] - 4s 255us/step - loss: 0.2153 - val_loss: 0.2388\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.22788\n",
            "Epoch 20/150\n",
            "14163/14163 [==============================] - 4s 266us/step - loss: 0.2131 - val_loss: 0.2074\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.22788 to 0.20739, saving model to /content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\n",
            "Epoch 21/150\n",
            "14163/14163 [==============================] - 4s 253us/step - loss: 0.2071 - val_loss: 0.2108\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.20739\n",
            "Epoch 22/150\n",
            "14163/14163 [==============================] - 4s 262us/step - loss: 0.2019 - val_loss: 0.2183\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.20739\n",
            "Epoch 23/150\n",
            "14163/14163 [==============================] - 4s 255us/step - loss: 0.1995 - val_loss: 0.2087\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.20739\n",
            "Epoch 24/150\n",
            "14163/14163 [==============================] - 4s 255us/step - loss: 0.1999 - val_loss: 0.1953\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.20739 to 0.19525, saving model to /content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\n",
            "Epoch 25/150\n",
            "14163/14163 [==============================] - 4s 254us/step - loss: 0.1933 - val_loss: 0.2149\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.19525\n",
            "Epoch 26/150\n",
            "14163/14163 [==============================] - 4s 254us/step - loss: 0.1914 - val_loss: 0.1963\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.19525\n",
            "Epoch 27/150\n",
            "14163/14163 [==============================] - 4s 259us/step - loss: 0.1875 - val_loss: 0.1885\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.19525 to 0.18851, saving model to /content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\n",
            "Epoch 28/150\n",
            "14163/14163 [==============================] - 4s 254us/step - loss: 0.1851 - val_loss: 0.1805\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.18851 to 0.18051, saving model to /content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\n",
            "Epoch 29/150\n",
            "14163/14163 [==============================] - 4s 254us/step - loss: 0.1831 - val_loss: 0.1825\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.18051\n",
            "Epoch 30/150\n",
            "14163/14163 [==============================] - 4s 251us/step - loss: 0.1804 - val_loss: 0.1750\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.18051 to 0.17498, saving model to /content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\n",
            "Epoch 31/150\n",
            "14163/14163 [==============================] - 4s 260us/step - loss: 0.1786 - val_loss: 0.1870\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.17498\n",
            "Epoch 32/150\n",
            "14163/14163 [==============================] - 4s 275us/step - loss: 0.1763 - val_loss: 0.1706\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.17498 to 0.17060, saving model to /content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\n",
            "Epoch 33/150\n",
            "14163/14163 [==============================] - 4s 282us/step - loss: 0.1758 - val_loss: 0.1877\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.17060\n",
            "Epoch 34/150\n",
            "14163/14163 [==============================] - 4s 275us/step - loss: 0.1740 - val_loss: 0.1796\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.17060\n",
            "Epoch 35/150\n",
            "14163/14163 [==============================] - 4s 261us/step - loss: 0.1724 - val_loss: 0.1654\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.17060 to 0.16543, saving model to /content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\n",
            "Epoch 36/150\n",
            "14163/14163 [==============================] - 4s 260us/step - loss: 0.1715 - val_loss: 0.1675\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.16543\n",
            "Epoch 37/150\n",
            "14163/14163 [==============================] - 4s 258us/step - loss: 0.1695 - val_loss: 0.1686\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.16543\n",
            "Epoch 38/150\n",
            "14163/14163 [==============================] - 4s 261us/step - loss: 0.1681 - val_loss: 0.1728\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.16543\n",
            "Epoch 39/150\n",
            "14163/14163 [==============================] - 4s 260us/step - loss: 0.1651 - val_loss: 0.1968\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.16543\n",
            "Epoch 40/150\n",
            "14163/14163 [==============================] - 4s 254us/step - loss: 0.1648 - val_loss: 0.1665\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.16543\n",
            "Epoch 41/150\n",
            "14163/14163 [==============================] - 3s 247us/step - loss: 0.1642 - val_loss: 0.1589\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.16543 to 0.15890, saving model to /content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\n",
            "Epoch 42/150\n",
            "14163/14163 [==============================] - 4s 254us/step - loss: 0.1632 - val_loss: 0.1688\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.15890\n",
            "Epoch 43/150\n",
            "14163/14163 [==============================] - 4s 261us/step - loss: 0.1607 - val_loss: 0.1753\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.15890\n",
            "Epoch 44/150\n",
            "14163/14163 [==============================] - 4s 260us/step - loss: 0.1601 - val_loss: 0.1846\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.15890\n",
            "Epoch 45/150\n",
            "14163/14163 [==============================] - 4s 257us/step - loss: 0.1603 - val_loss: 0.1631\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.15890\n",
            "Epoch 46/150\n",
            "14163/14163 [==============================] - 4s 253us/step - loss: 0.1601 - val_loss: 0.1597\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.15890\n",
            "Epoch 47/150\n",
            "14163/14163 [==============================] - 4s 261us/step - loss: 0.1590 - val_loss: 0.1535\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.15890 to 0.15350, saving model to /content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\n",
            "Epoch 48/150\n",
            "14163/14163 [==============================] - 3s 247us/step - loss: 0.1585 - val_loss: 0.1700\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.15350\n",
            "Epoch 49/150\n",
            "14163/14163 [==============================] - 4s 265us/step - loss: 0.1572 - val_loss: 0.1576\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.15350\n",
            "Epoch 50/150\n",
            "14163/14163 [==============================] - 4s 258us/step - loss: 0.1567 - val_loss: 0.1577\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.15350\n",
            "Epoch 51/150\n",
            "14163/14163 [==============================] - 4s 251us/step - loss: 0.1561 - val_loss: 0.1559\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.15350\n",
            "Epoch 52/150\n",
            "14163/14163 [==============================] - 4s 264us/step - loss: 0.1555 - val_loss: 0.1678\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.15350\n",
            "Epoch 53/150\n",
            "14163/14163 [==============================] - 4s 262us/step - loss: 0.1552 - val_loss: 0.1570\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.15350\n",
            "Epoch 54/150\n",
            "14163/14163 [==============================] - 4s 262us/step - loss: 0.1539 - val_loss: 0.1541\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.15350\n",
            "Epoch 55/150\n",
            "14163/14163 [==============================] - 4s 260us/step - loss: 0.1525 - val_loss: 0.1550\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.15350\n",
            "Epoch 56/150\n",
            "14163/14163 [==============================] - 4s 268us/step - loss: 0.1533 - val_loss: 0.1688\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.15350\n",
            "Epoch 57/150\n",
            "14163/14163 [==============================] - 4s 268us/step - loss: 0.1530 - val_loss: 0.1575\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.15350\n",
            "Epoch 58/150\n",
            "14163/14163 [==============================] - 4s 256us/step - loss: 0.1527 - val_loss: 0.1567\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.15350\n",
            "Epoch 59/150\n",
            "14163/14163 [==============================] - 4s 256us/step - loss: 0.1507 - val_loss: 0.1568\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.15350\n",
            "Epoch 60/150\n",
            "14163/14163 [==============================] - 4s 265us/step - loss: 0.1510 - val_loss: 0.1531\n",
            "\n",
            "Epoch 00060: val_loss improved from 0.15350 to 0.15308, saving model to /content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\n",
            "Epoch 61/150\n",
            "14163/14163 [==============================] - 4s 255us/step - loss: 0.1504 - val_loss: 0.1566\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.15308\n",
            "Epoch 62/150\n",
            "14163/14163 [==============================] - 4s 253us/step - loss: 0.1492 - val_loss: 0.1514\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.15308 to 0.15145, saving model to /content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\n",
            "Epoch 63/150\n",
            "14163/14163 [==============================] - 4s 258us/step - loss: 0.1492 - val_loss: 0.1541\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.15145\n",
            "Epoch 64/150\n",
            "14163/14163 [==============================] - 4s 257us/step - loss: 0.1487 - val_loss: 0.1578\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.15145\n",
            "Epoch 65/150\n",
            "14163/14163 [==============================] - 4s 252us/step - loss: 0.1488 - val_loss: 0.1518\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.15145\n",
            "Epoch 66/150\n",
            "14163/14163 [==============================] - 4s 255us/step - loss: 0.1482 - val_loss: 0.1498\n",
            "\n",
            "Epoch 00066: val_loss improved from 0.15145 to 0.14979, saving model to /content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\n",
            "Epoch 67/150\n",
            "14163/14163 [==============================] - 4s 253us/step - loss: 0.1474 - val_loss: 0.1590\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.14979\n",
            "Epoch 68/150\n",
            "14163/14163 [==============================] - 4s 262us/step - loss: 0.1489 - val_loss: 0.1503\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.14979\n",
            "Epoch 69/150\n",
            "14163/14163 [==============================] - 4s 259us/step - loss: 0.1479 - val_loss: 0.1443\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.14979 to 0.14429, saving model to /content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\n",
            "Epoch 70/150\n",
            "14163/14163 [==============================] - 4s 259us/step - loss: 0.1466 - val_loss: 0.1537\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.14429\n",
            "Epoch 71/150\n",
            "14163/14163 [==============================] - 4s 257us/step - loss: 0.1460 - val_loss: 0.1512\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.14429\n",
            "Epoch 72/150\n",
            "14163/14163 [==============================] - 4s 250us/step - loss: 0.1468 - val_loss: 0.1453\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.14429\n",
            "Epoch 73/150\n",
            "14163/14163 [==============================] - 4s 257us/step - loss: 0.1471 - val_loss: 0.1481\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.14429\n",
            "Epoch 74/150\n",
            "14163/14163 [==============================] - 4s 257us/step - loss: 0.1463 - val_loss: 0.1508\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.14429\n",
            "Epoch 75/150\n",
            "14163/14163 [==============================] - 4s 259us/step - loss: 0.1463 - val_loss: 0.1483\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.14429\n",
            "Epoch 76/150\n",
            "14163/14163 [==============================] - 4s 251us/step - loss: 0.1458 - val_loss: 0.1482\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.14429\n",
            "Epoch 77/150\n",
            "14163/14163 [==============================] - 4s 260us/step - loss: 0.1460 - val_loss: 0.1683\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.14429\n",
            "Epoch 78/150\n",
            "14163/14163 [==============================] - 4s 252us/step - loss: 0.1447 - val_loss: 0.1478\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.14429\n",
            "Epoch 79/150\n",
            "14163/14163 [==============================] - 4s 260us/step - loss: 0.1451 - val_loss: 0.1498\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.14429\n",
            "Epoch 80/150\n",
            "14163/14163 [==============================] - 4s 256us/step - loss: 0.1450 - val_loss: 0.1489\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.14429\n",
            "Epoch 81/150\n",
            "14163/14163 [==============================] - 4s 260us/step - loss: 0.1442 - val_loss: 0.1456\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.14429\n",
            "Epoch 82/150\n",
            "14163/14163 [==============================] - 4s 261us/step - loss: 0.1440 - val_loss: 0.1440\n",
            "\n",
            "Epoch 00082: val_loss improved from 0.14429 to 0.14397, saving model to /content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\n",
            "Epoch 83/150\n",
            "14163/14163 [==============================] - 4s 260us/step - loss: 0.1446 - val_loss: 0.1404\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.14397 to 0.14036, saving model to /content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\n",
            "Epoch 84/150\n",
            "14163/14163 [==============================] - 4s 258us/step - loss: 0.1444 - val_loss: 0.1444\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.14036\n",
            "Epoch 85/150\n",
            "14163/14163 [==============================] - 4s 260us/step - loss: 0.1440 - val_loss: 0.1504\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.14036\n",
            "Epoch 86/150\n",
            "14163/14163 [==============================] - 4s 253us/step - loss: 0.1435 - val_loss: 0.1495\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.14036\n",
            "Epoch 87/150\n",
            "14163/14163 [==============================] - 4s 260us/step - loss: 0.1440 - val_loss: 0.1454\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.14036\n",
            "Epoch 88/150\n",
            "14163/14163 [==============================] - 4s 256us/step - loss: 0.1440 - val_loss: 0.1445\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.14036\n",
            "Epoch 89/150\n",
            "14163/14163 [==============================] - 4s 261us/step - loss: 0.1440 - val_loss: 0.1556\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.14036\n",
            "Epoch 90/150\n",
            "14163/14163 [==============================] - 4s 260us/step - loss: 0.1417 - val_loss: 0.1513\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.14036\n",
            "Epoch 91/150\n",
            "14163/14163 [==============================] - 4s 256us/step - loss: 0.1436 - val_loss: 0.1448\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.14036\n",
            "Epoch 92/150\n",
            "14163/14163 [==============================] - 4s 254us/step - loss: 0.1423 - val_loss: 0.1429\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.14036\n",
            "Epoch 93/150\n",
            "14163/14163 [==============================] - 4s 259us/step - loss: 0.1431 - val_loss: 0.1468\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.14036\n",
            "Epoch 94/150\n",
            "14163/14163 [==============================] - 4s 248us/step - loss: 0.1436 - val_loss: 0.1425\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.14036\n",
            "Epoch 95/150\n",
            "14163/14163 [==============================] - 4s 254us/step - loss: 0.1426 - val_loss: 0.1436\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.14036\n",
            "Epoch 96/150\n",
            "14163/14163 [==============================] - 4s 264us/step - loss: 0.1426 - val_loss: 0.1441\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.14036\n",
            "Epoch 97/150\n",
            "14163/14163 [==============================] - 4s 261us/step - loss: 0.1419 - val_loss: 0.1449\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.14036\n",
            "Epoch 98/150\n",
            "14163/14163 [==============================] - 4s 262us/step - loss: 0.1422 - val_loss: 0.1433\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.14036\n",
            "Epoch 99/150\n",
            "14163/14163 [==============================] - 4s 260us/step - loss: 0.1423 - val_loss: 0.1457\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.14036\n",
            "Epoch 100/150\n",
            "14163/14163 [==============================] - 4s 254us/step - loss: 0.1420 - val_loss: 0.1404\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.14036\n",
            "Epoch 101/150\n",
            "14163/14163 [==============================] - 4s 251us/step - loss: 0.1416 - val_loss: 0.1444\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.14036\n",
            "Epoch 102/150\n",
            "14163/14163 [==============================] - 4s 248us/step - loss: 0.1422 - val_loss: 0.1410\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.14036\n",
            "Epoch 103/150\n",
            "14163/14163 [==============================] - 4s 257us/step - loss: 0.1417 - val_loss: 0.1520\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.14036\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfor train, test in kfold.split(H1):\\n  trainy, testy = Y[train], Y[test]\\n  traindata, testdata = H1[train], H1[test]\\n  mlp_2019  = mlp()\\n  mlp_2019.compile(optimizer=Adam(lr=0.0005),loss = 'mean_squared_error', metrics = ['accuracy'])\\n  mlp_2019.fit(traindata, trainy, epochs = 200, batch_size = 20, verbose=1, validation_split=0.1, callbacks = [checkpointer])\\n  error.append(mlp_2019.evaluate(testdata, testy))\\n\\n\\n#mlp_2019.fit_generator(kfoldcv(H1,Y)[0],validation_data = kfoldcv(H1,Y)[1], epochs = 150, steps_per_epoch = len(kfoldcv(H1,Y)[0][0]) ,\\n#                        validation_steps = len(kfoldcv(H1,Y)[1][0]), callbacks=[checkpointer])\\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1a9K_HOi1th",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rmse(p1, p2):\n",
        "  return np.sqrt(np.sum((p1-p2)**2, axis = 1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89vN141bjB7l",
        "colab_type": "code",
        "outputId": "39caa774-b363-4791-fb19-635e832655df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "m2  = load_model(\"/content/drive/My Drive/CTW_2019/CTW2019_mean_sqr2.h5\")\n",
        "l = 140\n",
        "r = 150\n",
        "pred = m2.predict(X_test)\n",
        "org = y_test\n",
        "print(pred[:,:-1].shape)\n",
        "print(org[:,:-1].shape)\n",
        "print(np.mean(rmse(pred, org)))\n",
        "print(np.mean(rmse(pred[:,:-1], org[:,:-1])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1749, 2)\n",
            "(1749, 2)\n",
            "0.6284134370585278\n",
            "0.274711075025098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp1SNKEkjB4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Isu3Gf2tQo4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "error = np.array(error)\n",
        "np.savetxt('/content/drive/My Drive/CTW_2019/test.out', x, delimiter=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTiHa5K6SlZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(Y.shape[0]):\n",
        "  if abs(Y[i,2]) > 1:\n",
        "    print(i) \n",
        "  else:\n",
        "    print(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qy27Tqdv-6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_ae(input_dim):\n",
        "  #Edit this\n",
        "  inp = Input(shape=(input_dim)) #56x77\n",
        "  x = Conv2D(4,(3,3),strides=(1,1),padding='same',,activation='relu')(inp)\n",
        "  x = MaxPooling2D((2, 2), padding='same')(x)    #28x39x4\n",
        "  x = Conv2D(8,(3,3),strides=(1,1),padding='same',activation='relu')(x)\n",
        "  x = MaxPooling2D((2, 2), padding='same')(x) #14x20x8\n",
        "  x = Conv2D(16,(3,2),strides=(1,1),padding='same',activation='relu')(x)\n",
        "  encoded = MaxPooling2D((3, 3), padding='same')(x) #5x7x16\n",
        "  x = Conv2D(16,(3,2),strides=(1,1),padding='same',activation='relu')(encoded)\n",
        "  x = UpSampling2D((3, 3))(x)\n",
        "  x = Conv2D(8,(3,3),strides=(1,1),padding='same',activation='relu')(x)\n",
        "  x = UpSampling2D((2, 2))(x)\n",
        "  x = Conv2D(4,(3,3),strides=(1,1),padding='same', activation='relu')(inp)\n",
        "  x = UpSampling2D((2, 2))(x)\n",
        "  decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "  return Model(inp, decoded), Model(inp, encoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENWEUTJ8yYhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_classifier(input_dim);\n",
        "  inp = Input(shape=(input_dim))\n",
        "  op = Dense(3,activation='sigmoid')(x)\n",
        "  return Model(inp, op)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6cSZ5bQ5lM_",
        "colab_type": "code",
        "outputId": "577d3372-31ca-490e-ef7f-7139cc2b3775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "y,y_v  = train_test_split(y, test_size=0.3, random_state=54) \n",
        "print(y.shape)\n",
        "steps = len(y)\n",
        "print(steps)\n",
        "val_Steps = len(y_v)\n",
        "print(val_Steps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5398, 5000)\n",
            "5398\n",
            "2314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQv2IiT85o8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder, autoencoder = create_model(inp_dim)\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "earlystopper = EarlyStopping(patience = 10, verbose=1)\n",
        "checkpointer = ModelCheckpoint('Best.h5', verbose=1, save_best_only=True)\n",
        "for i in range(200):\n",
        "    autoencoder.fit_generator(data_gen(y),validation_data = data_gen(y_v), epochs = 1, steps_per_epoch = steps ,\n",
        "                        validation_steps = len(y_v), callbacks=[earlystopper, checkpointer])\n",
        "model.save('mymodel2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sckNT8GJTzSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CLassifier\n",
        "\n",
        "def cls(inp):\n",
        "  inp = Input(shape=(inp,))\n",
        "  x = Dense(512, activation='relu')(inp)\n",
        "  x = Dropout(0.4)(x)\n",
        "  x = Dense(512, activation='softmax')(x)\n",
        "  return Model(inp, x)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}